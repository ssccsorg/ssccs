---
title: "Schema–Segment Composition Computing System"
subtitle: "A Structure-Defined, Constraint-Conditioned, and Observation-Centric Computational System Architecture"
format:
  html:
    execute:
        eval: true
        echo: false
    output-file: "index.html"
    embed-resources: true
    self-contained-math: true 
    minimal: true
    theme: minimal
    mainfont: "Georgia"
    code-font: "Source Code Pro"
    toc: true
    toc-title: "Contents"
    font-size: 11pt
    page-layout: full
    code-overflow: wrap
    include-in-header:
      text: |
        <style>
        a {
          text-decoration: none !important;
          color: #0d6efd;
        }
        </style>
  gfm:
    execute:
      eval: false
      echo: true
  pdf:
    default-figure-format: svg
    colorlinks: false
    toc-title: "Contents"
    execute:
        echo: false
    pdf-engine-opts: ["-shell-escape"]
    fig-format: svg
    papersize: a4
    graphics: true
    highlight-style: monochrome
    code-block-bg: false
    code-block-border-left: true
    fig-pos: 'H'
    fig-cap-location: bottom
    header-includes:
        - |
            \usepackage{authblk}
            \usepackage{svg}
            \svgsetup{inkscapepath=Whitepaper_files}
            \author{Taeho Lee}
            \affil{SSCCS gUG (i.G.)}
    include-in-header:
        text: |
            \usepackage{unicode-math}
            \addtokomafont{disposition}{\rmfamily}
            \usepackage{graphicx}            
            \setkeys{Gin}{width=\linewidth,height=\textheight,keepaspectratio}
            \usepackage{adjustbox}
            \let\oldincludegraphics\includegraphics
            \renewcommand{\includegraphics}[2][]{%
                \vspace{1em}%
                \maxsizebox{\linewidth}{\textheight}{%
                    \oldincludegraphics[#1]{#2}%
                }%
                \vspace{1em}%
            }
---

::: {.content-visible when-format="gfm"}

[![DOI](https://zenodo.org/badge/DOI/10.5281/zenodo.18787286.svg)](https://doi.org/10.5281/zenodo.18787286)

:::

## Abstract {.unnumbered .unlisted}

**SSCCS (Schema–Segment Composition Computing System)** is an infrastructure specification that redefines computation as the traceable projection of immutable Segments within a structured Scheme. While contemporary innovation focuses on material hardware shifts, SSCCS addresses fundamental inefficiencies of the Von Neumann bottleneck at the logical layer. By formalizing computation as the simultaneous resolution of static potential under dynamic constraints rather than a sequence of state mutations, the architecture reframes data movement, concurrency, and verifiability.

SSCCS enforces three core values: **Immutability** (data cannot be altered after creation), **Structural Integrity** (computation must respect declared schemas), and **Traceability** (every projection is cryptographically verifiable). These values are realized through a distinct computational ontology: Segments serve as immutable carriers of information, Schemes define structural boundaries and constraints, and Observation deterministically resolves these elements into a Projection without altering underlying data. This structure-defined approach eliminates hidden manipulation, minimizes data movement, and establishes an auditable infrastructure.

Driven by a software‑first philosophy, this architecture ensures deterministic reproducibility by completely decoupling execution logic from mutable state through structural and cryptographic isolation. This open specification, intended for validation across diverse domains, provides a roadmap where logical design dictates physical implementation, spanning from software emulation to hardware‑level support. By integrating intrinsic energy efficiency with high interpretability, SSCCS establishes a foundation for sustainable, accountable computational infrastructures, ultimately transitioning logic into a transparent, verifiable, and accessible Intellectual Public Commons.

::: {.content-visible when-format="pdf"}
{{< pagebreak >}}

\newpage
\tableofcontents
\newpage

{{< pagebreak >}}
::: 

## 1. Introduction  

For decades, computation has been defined by the von Neumann model:

```
Data + Program → Execution → Result
```

This formulation rests on several assumptions:

- Data exists as intrinsic values stored in memory.
- Programs are sequences of instructions that operate on data.
- Execution involves moving data between memory and processor.
- State mutation produces results.
- Time orders execution sequentially.

These assumptions, while deeply embedded, are not fundamental laws of computation but consequences of a particular architectural choice. SSCCS rejects this entire structure. In practice, the majority of energy and time in conventional systems is spent on moving data rather than on the actual arithmetic or logic operations [1, 2]—a symptom that reveals the underlying inefficiency of the von Neumann model. This imbalance, often called the "data‑movement wall" [3], has motivated research into alternative models.

SSCCS proposes a different set of primitives. Computation is not the transformation of values but the observation of structured potential. There are no mutable values, no instruction streams, and no privileged timeline. Instead, the system consists of:

- Segments: immutable points in a multi‑dimensional coordinate space.
- Schemes: immutable blueprints defining the geometry and relations among Segments.
- Fields: mutable containers of dynamic constraints.
- Observation: the sole active event that reveals a Projection—a specific configuration from the space of possibilities.

This redefinition has substantive consequences that extend far beyond data movement. The system's structure determines what can be known; observation determines what becomes known. Data movement reduction is one consequence among many—a derivative benefit of a shift from procedural execution to structural observation. More fundamentally, this shift yields deterministic reproducibility: because structure is fixed and observation is deterministic, every computation produces a verifiable trace from blueprint to projection.

The paper describes the formal components of SSCCS, their properties, the engineering implications (including but not limited to data movement reduction), the open specification format, the planned validation across multiple domains, and the project's commitment to computational infrastructure.

## 2. Background and Motivation  

### 2.1 The Von Neumann Inheritance  

The von Neumann architecture, developed in the 1940s, embedded certain philosophical assumptions into the fabric of computing: that computation is a process of change over time, that data and program are separate categories, and that meaning emerges from sequences of operations. These assumptions have proven remarkably durable, but they are not inevitable.

### 2.2 Symptoms of Architectural Assumptions  

The data movement problem is a symptom, not the disease. It arises because the von Neumann model requires data to be transported to a central processing unit, operated upon, and then returned to storage. This pattern repeats at every scale: from register files to caches to main memory to distributed systems. The energy and latency costs of this movement are well documented [1, 2, 4], but addressing them through incremental optimization—better caches, wider buses, smarter prefetching—treats the symptom while preserving the underlying model.

### 2.3 Concurrency as Afterthought  

Shared mutable state, the source of most concurrency complexity, is another consequence of the von Neumann model. Locks, atomic operations, cache coherence protocols, and the entire edifice of concurrent programming exist to manage the conflicts that arise when multiple agents can modify the same storage location. These mechanisms add further data movement and energy consumption, while also creating opacity: the behavior of concurrent systems becomes notoriously difficult to predict or verify.

### 2.4 The Black Box Problem  

Traditional computing treats the internal logic of execution as a black box. Programs accept inputs and produce outputs, but the path between them—the sequence of state mutations—is hidden unless explicitly traced. This opacity has profound consequences: software can contain undetected bugs, hidden backdoors, or inefficient pathways that remain invisible to users and auditors. Verification becomes a post-hoc activity rather than an intrinsic property of the system.

SSCCS addresses these issues not by optimizing them but by rendering them unnecessary. By making all persistent data immutable and replacing execution with observation, the model eliminates the root causes of data movement, synchronization overhead, and computational opacity.

## 3. The SSCCS Model  

SSCCS comprises three ontologically distinct layers, each irreducible to the others:

```{dot}
//| label: fig-ontology
//| fig-cap: "SSCCS Ontology: Three irreducible layers"
digraph SSCCS_Ontology {
    node [shape=rect];
    
    // Static Infrastructure: Immutable physical coordinates (S1 is defined but not utilized)
    node [shape=point, width=0.2, height=0.2];
    s1 [xlabel="Segment 1(S₁)\nNOT USED"];
    s2 [xlabel="Segment 2(S₂)"];
    s3 [xlabel="Segment 3(S₃)"];
    
    // Structural Blueprint: Topological configuration of segments
    Scheme [label="Scheme (Σ₁)", shape=rect];
    
    // Dynamic Governance: The medium for constraints and field propagation
    Field [label="Field (F₁)\ngovernance, constraints, ...", shape=rect];
    
    // Computation Event: The triggering observation that initiates projection
    Observation [label="Observation (Ω₁)", shape=ellipse];
    
    // Manifested State: The output of the field under observation
    Projection [label="Projection (P₁)\n", shape=box];

    // Final Deterministic State: Interpreted data from the projection
    Data [label="Collapsed Possibility, State, or Data (D₁)\nD₁ = I₁(P₁)",shape=box, style=rounded, penwidth=2];
    
    // Structural Binding: Defines the static relationship between Scheme and Segments
    {rank=source;
        edge [arrowhead=none, style=solid];
        Scheme -> s2;
        Scheme -> s3;
    }
    
    // Structural Input: Topology and Segments define the Field's boundary conditions
    edge [arrowhead=normal];
    Scheme -> Field;

    edge [arrowhead=normal];
    s2 -> Field;
    s3 -> Field;

    // Trigger Mechanism: Observation acts as the operator on the Field
    edge [arrowhead=normal, style=solid];
    Observation -> Field [label="Ω: Computation Event"];
    
    // Resultant Projection: Field manifests the state through the observation operator
    Field -> Projection [label="P₁ = Ω₁(F(Σ(S₂,S₃)))"];

    // Data Derivation: The final step of interpreting physical projection into data
    Projection -> Data [label="Interpretion (I₁)"];
}
```

Simply the Field governs the observation of the Scheme and its Segments, producing a Projection that can be interpreted as data. Each layer has defined properties and relationships; together they constitute the complete computational ontology.

- Immutable Segments & Schemes allow any number of observers to apply Ω concurrently – no locks or synchronization needed.
- Structural mapping eliminates data movement: the von Neumann bottleneck disappears by design.
- Consistency is guaranteed by the single mutable layer (Field), which governs all observations.
- Deterministic results arise from cryptographic identities and reproducible hardware mappings.
- Parallelism is emergent: concurrency flows from structure, not from explicit programming.

```{dot}
//| label: fig-ssccs-multifield
//| fig-cap: "SSCCS multi-field, multi-observation parallel model with segment set"
digraph SSCCS_MultiField {
    node [shape=rect];
    
    // === Leftmost rank: Segments and Schemes (immutable) ===
    { rank=source;
        // Segments (atomic coordinates)
        node [shape=point, width=0.2, height=0.2];
        s1 [xlabel="S₁"];
        s2 [xlabel="S₂"];
        s3 [xlabel="S₃"];
        s4 [xlabel="S₄"];
        s5 [xlabel="S₅"];
        s6 [xlabel="S₆"];
        s7 [xlabel="S₇"];
        s8 [xlabel="S₈"];
        
        // Schemes (structural blueprints)
        node [shape=box, style=solid];
        sch1 [label="Σ₁"];
        sch2 [label="Σ₂"];
        sch3 [label="Σ₃"];
        sch4 [label="Σ₄"];
        
        // Arrange in order: all segments then all schemes (will stack vertically)
        // We don't need to specify order; DOT will place them in the order they appear.
    }
    
    // === Second rank: Fields (dynamic governance) ===
    { rank=2;
        node [shape=rect, style=dashed];
        f1 [label="F₁"];
        f2 [label="F₂"];
        f3 [label="F₃"];
    }
    { rank=same; f1; f2; f3; }
    
    // === Third rank: Observation events ===
    { rank=3;
        node [shape=ellipse];
        o1 [label="Ω₁"];
        o2 [label="Ω₂"];
        o3 [label="Ω₃"];
        o4 [label="Ω₄"];
        o5 [label="Ω₅"];
    }
    { rank=same; o1; o2; o3; o4; o5; }
    
    // === Fourth rank: Projections (manifested states) ===
    { rank=4;
        node [shape=box];
        p1 [label="P₁"];
        p2 [label="P₂"];
        p3 [label="P₃"];
        p4 [label="P₄"];
        p5 [label="P₅"];
    }
    { rank=same; p1; p2; p3; p4; p5; }
    
    // === Fifth rank: Interpreted Data (final deterministic values) ===
    { rank=5;
        node [shape=box, style=rounded, penwidth=2];
        d1 [label="D₁\n= I₁(P₁)"];
        d2 [label="D₂\n= I₂(P₂)"];
        d3 [label="D₃\n= I₃(P₃)"];
        d4 [label="D₄\n= I₄(P₄)"];
        d5 [label="D₅\n= I₅(P₅)"];
    }
    { rank=same; d1; d2; d3; d4; d5; }
    
    // === Scheme–Segment structural relations (undirected lines) ===
    edge [arrowhead=none, style=solid];
    sch1 -> s1; sch1 -> s2; sch1 -> s3;
    sch2 -> s2; sch2 -> s4; sch2 -> s5; sch2 -> s6;
    sch3 -> s3; sch3 -> s5; sch3 -> s7; sch3 -> s8;
    sch4 -> s1; sch4 -> s4; sch4 -> s6; sch4 -> s8;
    
    // === Field influences on Schemes and Segments (dashed) ===
    edge [arrowhead=none, style=dashed];
    f1 -> sch1; f1 -> sch2; f1 -> s1; f1 -> s2; f1 -> s4;
    f2 -> sch2; f2 -> sch3; f2 -> s3; f2 -> s5; f2 -> s7;
    f3 -> sch3; f3 -> sch4; f3 -> s6; f3 -> s8;
    
    // === Structural input: Schemes and Segments define Field boundaries (solid) ===
    edge [arrowhead=normal, style=solid];
    sch1 -> f1; sch2 -> f1; sch2 -> f2; sch3 -> f2; sch3 -> f3; sch4 -> f3;
    s1 -> f1; s2 -> f1; s3 -> f2; s4 -> f1; s5 -> f2; s6 -> f3; s7 -> f2; s8 -> f3;
    
    // === Trigger mechanism: Each Observation applies to a Field ===
    edge [arrowhead=normal, style=solid];
    o1 -> f1 [label="Ω"];
    o2 -> f1 [label="Ω"];
    o3 -> f2 [label="Ω"];
    o4 -> f2 [label="Ω"];
    o5 -> f3 [label="Ω"];
    
    // === Field manifests Projection under observation ===
    f1 -> p1 [label="P₁ = Ω₁(F₁)"];
    f1 -> p2 [label="P₂ = Ω₂(F₁)"];
    f2 -> p3 [label="P₃ = Ω₃(F₂)"];
    f2 -> p4 [label="P₄ = Ω₄(F₂)"];
    f3 -> p5 [label="P₅ = Ω₅(F₃)"];
    
    // === Interpretation: Projection yields deterministic Data ===
    edge [arrowhead=normal, style=solid];
    p1 -> d1 [label="I₁"];
    p2 -> d2 [label="I₂"];
    p3 -> d3 [label="I₃"];
    p4 -> d4 [label="I₄"];
    p5 -> d5 [label="I₅"];
}
```

This integrated view illustrates the full SSCCS model: The observation events ($Ω_1$, $Ω_2$, etc.) can occur concurrently without any temporal ordering, and the resulting projections ($P_1$, $P_2$, etc.) are independent of each other. The data ($D_1$, $D_2$, $D_3$, etc.) derived from these projections can also be interpreted independently. So **time is not a fundamental dimension that governs state changes**; instead, the structure of Schemes and the constraints of Fields govern what can be observed and when.

A more complexier structural composition can be defined like:

```{dot}
//| label: fig-ssccs-multifield
//| fig-cap: "The large-scale mass-segment scenario"
digraph SSCCS_MultiField {
    rankdir=TB;
    node [shape=rect];
    
    ranksep=0.1;
    nodesep=0.13;
    
    // === Row 1: Segments 1–6 + invisible (to make 7 columns) ===
    { rank=1;
        node [shape=point, width=0.2, height=0.2];
        s1 [xlabel="S₁"]; s2 [xlabel="S₂"]; s3 [xlabel="S₃"]; s4 [xlabel="S₄"]; s5 [xlabel="S₅"]; s6 [xlabel="S₆"];
        node [style=invis, shape=point, label="", width=0, height=0];
        invis_s1;
    }
    // === Row 2: Segments 7–12 + invisible ===
    { rank=2;
        node [shape=point, width=0.2, height=0.2];
        s7 [xlabel="S₇"]; s8 [xlabel="S₈"]; s9 [xlabel="S₉"]; s10 [xlabel="S₁₀"]; s11 [xlabel="S₁₁"]; s12 [xlabel="S₁₂"];
        node [style=invis, shape=point, label="", width=0, height=0];
        invis_s2;
    }
    // === Row 3: Segments 13–18 + invisible ===
    { rank=3;
        node [shape=point, width=0.2, height=0.2];
        s13 [xlabel="S₁₃"]; s14 [xlabel="S₁₄"]; s15 [xlabel="S₁₅"]; s16 [xlabel="S₁₆"]; s17 [xlabel="S₁₇"]; s18 [xlabel="S₁₈"];
        node [style=invis, shape=point, label="", width=0, height=0];
        invis_s3;
    }
    // === Row 4: Segments 19–24 + invisible ===
    { rank=4;
        node [shape=point, width=0.2, height=0.2];
        s19 [xlabel="S₁₉"]; s20 [xlabel="S₂₀"]; s21 [xlabel="S₂₁"]; s22 [xlabel="S₂₂"]; s23 [xlabel="S₂₃"]; s24 [xlabel="S₂₄"];
        node [style=invis, shape=point, label="", width=0, height=0];
        invis_s4;
    }
    
    // === Row 5: Schemes (structural blueprints) – widened to 7 columns ===
    { rank=5;
        node [shape=box, style=solid];
        sch1 [label="Σ₁"]; sch2 [label="Σ₂"]; sch3 [label="Σ₃"]; sch4 [label="Σ₄"];
        node [style=invis, shape=point, label=""];
        invis_sch1; invis_sch2; invis_sch3;
    }
    
    // === Row 6: Fields (dynamic governance) – widened to 7 columns ===
    { rank=6;
        node [shape=rect, style=dashed];
        f1 [label="F₁"]; f2 [label="F₂"]; f3 [label="F₃"]; f4 [label="F₄"];
        node [style=invis, shape=point, label=""];
        invis_f1; invis_f2; invis_f3;
    }
    
    // === Row 7: Observation events ===
    { rank=7;
        node [shape=ellipse];
        o1 [label="Ω₁"]; o2 [label="Ω₂"]; o3 [label="Ω₃"]; o4 [label="Ω₄"]; o5 [label="Ω₅"]; o6 [label="Ω₆"]; o7 [label="Ω₇"];
    }
    
    // === Row 8: Projections (manifested states) ===
    { rank=8;
        node [shape=box];
        p1 [label="P₁"]; p2 [label="P₂"]; p3 [label="P₃"]; p4 [label="P₄"]; p5 [label="P₅"]; p6 [label="P₆"]; p7 [label="P₇"];
    }
    
    // === Row 9: Interpreted Data (final deterministic values) ===
    { rank=9;
        node [shape=rect, style=rounded, penwidth=2];
        d1 [label="D₁\n= I₁(P₁)"]; 
        d2 [label="D₂\n= I₂(P₂)"]; 
        d3 [label="D₃\n= I₃(P₃)"];
        d4 [label="D₄\n= I₄(P₄)"]; 
        d5 [label="D₅\n= I₅(P₅)"]; 
        d6 [label="D₆\n= I₆(P₆)"];
        d7 [label="D₇\n= I₇(P₇)"];
    }
    
    // === Scheme–Segment structural relations (undirected lines) ===
    edge [arrowhead=none, style=solid];
    sch1 -> s1; sch1 -> s2; sch1 -> s3; sch1 -> s4; sch1 -> s5; sch1 -> s6;
    sch2 -> s5; sch2 -> s6; sch2 -> s7; sch2 -> s8; sch2 -> s9; sch2 -> s10; sch2 -> s11; sch2 -> s12;
    sch3 -> s10; sch3 -> s11; sch3 -> s12; sch3 -> s13; sch3 -> s14; sch3 -> s15; sch3 -> s16; sch3 -> s17; sch3 -> s18;
    sch4 -> s15; sch4 -> s16; sch4 -> s17; sch4 -> s18; sch4 -> s19; sch4 -> s20; sch4 -> s21; sch4 -> s22; sch4 -> s23; sch4 -> s24;
    
    // === Field influences on Schemes and Segments (dashed) ===
    edge [arrowhead=none, style=dashed];
    f1 -> sch1; f1 -> sch2;
    f1 -> s1; f1 -> s2; f1 -> s3; f1 -> s4; f1 -> s5; f1 -> s6; f1 -> s7; f1 -> s8; f1 -> s9; f1 -> s10; f1 -> s11; f1 -> s12;
    f2 -> sch2; f2 -> sch3;
    f2 -> s8; f2 -> s9; f2 -> s10; f2 -> s11; f2 -> s12; f2 -> s13; f2 -> s14; f2 -> s15; f2 -> s16; f2 -> s17; f2 -> s18;
    f3 -> sch3; f3 -> sch4;
    f3 -> s14; f3 -> s15; f3 -> s16; f3 -> s17; f3 -> s18; f3 -> s19; f3 -> s20; f3 -> s21; f3 -> s22; f3 -> s23; f3 -> s24;
    f4 -> sch1; f4 -> sch4;
    f4 -> s1; f4 -> s3; f4 -> s5; f4 -> s18; f4 -> s20; f4 -> s22;
    
    // === Structural input: Schemes and Segments define Field boundaries (solid) ===
    edge [arrowhead=normal, style=solid];
    sch1 -> f1; sch1 -> f4;
    sch2 -> f1; sch2 -> f2;
    sch3 -> f2; sch3 -> f3;
    sch4 -> f3; sch4 -> f4;
    s1 -> f1; s2 -> f1; s3 -> f1; s4 -> f1; s5 -> f1; s6 -> f1; s7 -> f1; s8 -> f1; s9 -> f1; s10 -> f1; s11 -> f1; s12 -> f1;
    s8 -> f2; s9 -> f2; s10 -> f2; s11 -> f2; s12 -> f2; s13 -> f2; s14 -> f2; s15 -> f2; s16 -> f2; s17 -> f2; s18 -> f2;
    s14 -> f3; s15 -> f3; s16 -> f3; s17 -> f3; s18 -> f3; s19 -> f3; s20 -> f3; s21 -> f3; s22 -> f3; s23 -> f3; s24 -> f3;
    s1 -> f4; s3 -> f4; s5 -> f4; s18 -> f4; s20 -> f4; s22 -> f4;
    
    // === Trigger mechanism: Each Observation applies to one or more Fields ===
    edge [arrowhead=normal, style=solid];
    o1 -> {f1, f2};
    o2 -> {f1, f4};
    o3 -> {f2, f3};
    o4 -> {f3, f4};
    o5 -> f1;
    o6 -> f2;
    o7 -> {f1, f2, f3};

    edge [arrowhead=normal, style=solid];
    {f1, f2} -> p1 [label="Ω₁"];
    {f1, f4} -> p2 [label="Ω₂"];
    {f2, f3} -> p3 [label="Ω₃"];
    {f3, f4} -> p4 [label="Ω₄"];
    f1 -> p5 [label="Ω₅"];
    f2 -> p6 [label="Ω₆"];
    {f1, f2, f3} -> p7 [label="Ω₇"];
    
    // === Interpretation: Projection yields deterministic Data ===
    edge [arrowhead=normal, style=solid];
    p1 -> d1 [label="I₁"];
    p2 -> d2 [label="I₂"];
    p3 -> d3 [label="I₃"];
    p4 -> d4 [label="I₄"];
    p5 -> d5 [label="I₅"];
    p6 -> d6 [label="I₆"];
    p7 -> d7 [label="I₇"];
}
```

### 3.1 Segment: Atomic Coordinate Existence  

A Segment is the minimal unit of potential—the fundamental building block of the SSCCS universe. Formally, a Segment $s$ is a tuple $(c, id)$ where $c \in \mathbb{R}^d$ (or a discrete lattice) represents coordinates in a $d$-dimensional possibility space, and $id = H(c)$ is a cryptographic hash providing a unique identifier.

Its properties are:

- Immutability: once created, a Segment cannot be modified; it can only be referenced.
- Statelessness: it contains no values, strings, or data structures—only coordinates and identity.

Formally, a Segment $s$ is defined as a tuple $(c, id)$ where $c \in \mathbb{R}^d$ (or a discrete lattice) represents coordinates in a $d$-dimensional possibility space, and $id = H(c)$ is a cryptographic hash providing a unique identifier.

A Segment does not define meaning, dimensionality, or adjacency. It merely exists as a coordinate point. Because Segments contain no mutable state, they can be observed concurrently by any number of observers without synchronization. The cryptographic identity ensures that every Segment is uniquely and verifiably identifiable.

### 3.2 Scheme: Structural Blueprint  

If Segment is existence, Scheme is structure.

A Scheme is an immutable blueprint that defines:

- Dimensional axes: specification of coordinate systems.
- Internal structural constraints: rules governing Segment relations.
- Adjacency relations: which Segments are neighbors in possibility space.
- Memory layout semantics: how structural relations map to physical storage.
- Observation rules: how observation resolves constraints into projections.

A Scheme defines a geometric arrangement of Segments, not a sequence of operations. Segment relationships are spatial rather than temporal. During compilation, the compiler maps these spatial relationships directly to hardware addresses, ensuring that Segments which are structurally adjacent become physically adjacent. This design makes locality an inherent property of the specification, eliminating the need for runtime optimizations.


### 3.3 Field: Dynamic Constraint Substrate  

The Field $F$ is the only mutable layer, but it does not store values. Instead, it stores admissibility conditions that dynamically constrain which configurations of Segments are possible at any given time. The Field can be thought of as a mutable set of rules or conditions that interact with the immutable structure defined by the Scheme.

It contains:

- External constraints: rules and conditions that are not part of the immutable Scheme but affect observation.
- Relational topology: the dynamic structure of how constraints relate to one another.
- Observation frontier: regions of the constraint space that have already been observed and collapsed.

Formally, $F$ is a set of admissibility predicates over the configuration space defined by $\Sigma$. Mutating $F$ changes which configurations are possible, but does not modify any Segment.

### 3.4 Observation and Projection  

Observation is the single active event. It is defined as:

$$ P = \Omega(\Sigma, F) $$

where  
- $\Sigma$ is the set of Segments and their Scheme,  
- $F$ is the current Field state,  
- $\Omega$ is the observation operator,  
- $P$ is the resulting Projection.

Observation occurs when the structure and Field together create an instability—i.e., multiple admissible configurations. $\Omega$ deterministically selects one configuration and returns it as $P$. No data is moved during observation; Segments remain in place. The Projection is ephemeral; if needed again, it is recomputed.

### 3.5 Secure Isolation and Cryptographic Boundaries  

SSCCS provides natural isolation through:

- Identity-based boundaries: Every Segment and Scheme has a unique cryptographic hash. A computation can only access Segments for which it holds valid references.
- Isolation through immutability: Since Segments cannot be modified, concurrent observations are naturally isolated.
- Cryptographically enforced scoping: Schemes can define boundaries limiting visibility, enforced by observation rules and identity verification.

This architecture enables complex computations within cryptographically enforced boundaries without requiring trust between components.

### 3.6 Relationship with Traditional Concepts  

| Traditional Concept   | SSCCS Counterpart          | Shift                          |
|-----------------------|----------------------------|--------------------------------|
| Instruction fetch     | Not applicable             | No imperative control flow     |
| Operand load          | Segment coordinates        | Data never moves; only observed|
| Result store          | Projection (ephemeral)     | Results are events, not states |
| Cache line fill       | Structural layout          | Locality from geometry         |
| Lock acquisition      | Immutability               | No shared mutable state        |
| Program counter       | Coordinate dimension       | Time as coordinate             |
| Algorithm             | Geometry                   | Structure determines observation|
| Black box execution   | Transparent projection     | Computation is auditable       |
 
## 4. Formal Properties  

### 4.1 Immutability and Concurrency  

Because Segments are immutable, any number of observations can be performed simultaneously without interference. Formally, if $S_1$ and $S_2$ are disjoint sets of Segments, then:

$$ \Omega(S_1 \cup S_2, F) = \Omega(S_1, F) \times \Omega(S_2, F) $$

where $\times$ denotes independent composition of projections. This property enables implicit parallelism without any programmer effort or runtime synchronisation—a consequence of immutability, not a feature added to address performance.

### 4.2 Determinism and Auditability  

Observation is deterministic: for identical $\Sigma$ and $F$, $\Omega$ always yields the same $P$. Determinism follows from the fact that selection among admissible configurations is a function of structure and constraints only. This enables auditability: every projection is a verifiable trace from blueprint to output.

### 4.3 Time as a Coordinate  

Time is treated as one coordinate axis among many. Temporal ordering is expressed by comparing coordinates along that axis. Observations do not have a global temporal order unless explicitly defined. This eliminates the notion of a "program counter" and the associated assumption that computation must proceed in sequence.

```{dot}
//| label: fig-time-coordinate
//| fig-cap: "Time as a coordinate axis"
digraph SSCCS_Comparison {
    rankdir=LR;
 
    // Sequential cluster (left)
    subgraph cluster_sequential {
        label="Sequential (von Neumann)";
        labelloc=t;
        style=dashed;
        node [shape=box, fontsize=10];
        edge [arrowhead=normal];
        
        s0 [label="State A\n(t=0)"];
        s1 [label="State B\n(t=1)"];
        s2 [label="State C\n(t=2)"];
        
        s0 -> s1 -> s2;
        
        note_seq [shape=plaintext, label="Time flows, state mutates", fontsize=11];
    }

    // Spatial cluster (right)
    subgraph cluster_spatial {
        label="Spatial (SSCCS)";
        labelloc=t;
        style=dashed;
        
        // Scheme‑segments (coordinates in space‑time)
        node [shape=point, width=0.2, height=0.2];
        p0 [xlabel="(t=0, x=1)"];
        p1 [xlabel="(t=2, x=3)"];
        p2 [xlabel="(t=5, x=2)"];

        // Field – drawn as a rectangle around points (using a subgraph)
        subgraph cluster_field {
            label="Field (rules + constraints)";
            style=dashed;
            color=black;
            node [shape=point];  // keep points inside
            p0; p1; p2;
        }

        // Observation events – projections
        node [shape=box, fontsize=10];
        proj0 [label="projection: A"];
        proj1 [label="projection: B"];
        proj2 [label="projection: C"];

        // Observation arrows
        edge [arrowhead=normal, style=solid, label="observe"];
        p0 -> proj0;
        p1 -> proj1;
        p2 -> proj2;

        // No arrows between scheme‑segments
        note_spatial [shape=plaintext, fontsize=9, label=
            "No persistent state – only coordinates + fields.\nObservation yields projections we interpret as 'state'."];
    }

    // Invisible edge to align clusters horizontally (optional)
    edge [style=invis];
    s2 -> p0;
}
```

### 4.4 Energy Model  

A simplified energy model for SSCCS is:

$$
E_{\text{total}} = E_{\text{observation}} \times N_{\text{obs}} + E_{\text{field-update}} \times N_{\text{update}}
$$

where $E_{\text{observation}}$ is the energy to perform one observation, and $E_{\text{field-update}}$ is the energy to modify the Field. There is no term for moving data between memory and processor, because Segments are stationary.
  
## 5. Compilation and Structural Mapping

A key engineering contribution of SSCCS is that the compiler, rather than generating a sequence of instructions, performs structural mapping of the Schema onto the target hardware. The compiler analyses the adjacency relations and memory layout semantics declared in the Schema (written in the open `.ss` format) and produces a physical placement of Segments that maximises locality.

For example, if a Schema defines a two‑dimensional grid of Segments with nearest‑neighbour adjacency, the compiler can lay out those Segments in memory in row‑major or column‑major order such that adjacent Segments occupy adjacent cache lines or even the same cache line. This is analogous to data layout optimisations performed manually in high‑performance computing, but here it is automated and guaranteed by the Schema's specification.

Furthermore, because the Schema encodes parallelism implicitly (independent subgraphs can be observed concurrently), the compiler can automatically generate code for vector units, multiple cores, or even custom hardware without explicit parallel annotations.

```{dot}
//| label: fig-compilation-process
//| fig-cap: "Compiler pipeline: from Schema to hardware layout"
digraph Compilation_Process {
    rankdir=TB;
    node [shape=rect, style=rounded];
    
    Schema [label=".ss Schema"];
    Hardware [label="Hardware Layout"];
    
    subgraph cluster_compiler {
        label="Compiler";
        style=rounded;
        
        // 컴파일러 내부 단계를 수평으로 배치
        { rank=same; Parse; Analysis; Layout; Map; CodeGen; }
        
        Parse [label="1. Parsing\n& Validation"];
        Analysis [label="2. Structural\nAnalysis"];
        Layout [label="3. Memory‑Layout\nResolution"];
        Map [label="4. Hardware\nMapping"];
        CodeGen [label="5. Observation‑Code\nGeneration"];
        
        Parse -> Analysis -> Layout -> Map -> CodeGen;
    }
    
    Schema -> Parse;
    CodeGen -> Hardware [label="emit layout & code"];
}
```


### 5.1 Compiler Pipeline

The SSCCS compiler transforms a high‑level `.ss` schema into a hardware‑specific layout through a deterministic pipeline.

1. Parsing and Validation: The `.ss` file is parsed into an intermediate representation (IR) that captures the Schema's axes, Segments, structural relations, constraints, memory‑layout declarations, and observation rules. Cryptographic identities (SchemaId, SegmentId) are computed and verified.

2. Structural Analysis: The compiler extracts adjacency, hierarchy, dependency, and equivalence relations from the Schema's relation graph. It identifies independent sub‑graphs that can be observed concurrently and detects any structural conflicts (e.g., cycles that would prevent deterministic observation).

3. Memory‑Layout Resolution: Using the Schema's `MemoryLayout` specification, the compiler resolves the mapping from coordinate space to logical addresses. The `MemoryLayout` struct contains a `layout_type` (Linear, RowMajor, ColumnMajor, SpaceFillingCurve, etc.) and a mapping function that implements the coordinate‑to‑address transformation. This stage produces a logical address map that preserves locality as defined by the adjacency relations.

4. Hardware Mapping: The logical address map is projected onto the target hardware's physical memory hierarchy. The compiler considers cache‑line boundaries, bank interleaving, and (where available) processing‑in‑memory (PIM) capabilities to place Segments such that structurally adjacent Segments reside in physically proximate storage locations (e.g., same cache line, adjacent memory banks). This step guarantees that observation can proceed with minimal data movement.

5. Observation‑Code Generation: For each independent sub‑graph, the compiler emits native code (or configures a reconfigurable fabric) that implements the observation operator `Ω`. The generated code respects the resolution strategy, triggers, and priority defined in the Schema's `ObservationRules`.

The entire pipeline is deterministic and reproducible: given the same `.ss` specification and target hardware profile, the compiler always produces the same layout and observation code.

#### Concrete Example: Compiling a Grid2DTemplate

Consider a simple 3×3 grid defined by a `Grid2DTemplate` (expressed here in a language‑neutral pseudocode):

```
grid = Grid2DTemplate(
    axes: ["x": 0..2, "y": 0..2],
    topology: FourConnected,
    memory_layout: RowMajor
)
```

The compiler processes this Schema as follows:

- Parsing: The schema is parsed into an internal representation with two discrete axes, nine Segments (coordinates (0,0) … (2,2)), adjacency relations for four‑connected neighbors, and a row‑major memory layout.
- Structural Analysis: The relation graph reveals that each interior cell has four neighbors; the graph is regular and contains no cycles that would create observational dependencies. All nine cells are mutually independent and can be observed in parallel.
- Memory‑Layout Resolution: The row‑major mapping function computes logical offsets: `offset = y * 3 + x`. The compiler evaluates this for all nine coordinates, producing a logical‑address map:
  ```
  (0,0)→0, (1,0)→1, (2,0)→2,
  (0,1)→3, … , (2,2)→8.
  ```
- Hardware Mapping: On a CPU with 64‑byte cache lines, the compiler packs the logical addresses into physical cache lines. Offsets 0‑7 fit into a single cache line; offset 8 spills into a second line. The compiler may decide to pad the layout to keep the entire grid in one cache line, or it may accept the spill because adjacent rows are still in adjacent lines.
- Observation‑Code Generation: For a trivial observation that reads each Segment's value, the compiler emits a loop that iterates over the nine logical addresses and loads the corresponding data. Because the addresses are consecutive, the loop can be vectorized (SIMD). If the observation is a reduction (e.g., sum of values), the compiler may generate a parallel reduction using multiple cores.

This example illustrates how the pipeline turns a declarative geometric description into efficient, hardware‑aware executable code without any manual optimization.

## 5.2 Memory Mapping Logic

The compiler’s ability to eliminate data movement hinges on the MemoryLayout abstraction. A `MemoryLayout` consists of:

- layout_type – a classification (`Linear`, `RowMajor`, `ColumnMajor`, `SpaceFillingCurve`, `Hierarchical`, `GraphBased`, `Custom`) describing the high‑level organisation.
- mapping – a function that, given a coordinate tuple (e.g., `(x, y, z)`), returns an optional logical address. This function is defined declaratively in the Schema and is independent of any programming language.
- metadata – a set of key‑value pairs providing implementation‑specific hints (e.g., curve parameters, stride lengths).

A logical address is an intermediate representation consisting of a segment identifier and an offset within that segment’s conceptual address space. It is not a physical memory address; rather, it serves as an intermediate coordinate that the hardware mapper later translates to concrete physical locations (cache lines, memory banks, etc.).

Example: For a two‑dimensional grid with row‑major layout, the mapping function can be expressed mathematically as:

```
f(x, y) = (grid_id, y·width + x)
```

where `width` is the grid’s extent in the x‑direction. The compiler evaluates this function for every coordinate in the Schema, producing a complete logical‑address map.

By decoupling the logical layout from the physical implementation, the same Schema can be projected onto vastly different hardware topologies:

- CPU caches – Adjacent logical addresses are placed into the same cache line or neighbouring lines.
- FPGA block RAM – The logical‑to‑physical mapping can be realised as a simple address decoder.
- HBM (High‑Bandwidth Memory) stacks – Segments with high adjacency can be distributed across multiple memory channels to exploit parallelism.
- Emerging non‑volatile memories (e.g., resistive RAM) – The stationary data model of SSCCS aligns naturally with processing‑in‑memory (PIM) architectures, where computation is performed directly inside the memory arrays.

In all cases, the mapping is deterministic and reproducible: given the same Schema and hardware profile, the compiler always produces the same physical layout, ensuring that observation proceeds with minimal data movement. 

### 5.3 Automating Manual Optimizations

The following table summarises how traditional manual optimisations become automatic consequences of structural specification in SSCCS:

| Manual Optimization     | SSCCS Mechanism                                      |
|-------------------------|------------------------------------------------------|
| Data layout orchestration | Schema defines geometry; compiler maps to hardware |
| Cache alignment         | Adjacency relations determine physical proximity     |
| SIMD vectorization      | Independent subgraphs imply vectorizable operations  |
| Thread scheduling       | Parallel structure maps to independent cores        |
| Lock management         | Immutability eliminates need for locks               |
| Execution strategy selection | Observation rules and structural independence guide parallel execution |
 

### 5.4 Example: Vector Addition with Rust Example

Consider the addition of two vectors of length $N$. This example demonstrates the transition from procedural execution to structural observation.

#### Traditional Approach (von Neumann)

In a traditional architecture, a loop iterates over indices, loading each element $a[i]$ and $b[i]$ from memory into registers, performing the addition, and storing the result back to memory.

```rust
// Rust-like pseudocode
fn add_vectors(a: &[f64], b: &[f64]) -> Vec<f64> {
    assert_eq!(a.len(), b.len());
    let mut result = Vec::with_capacity(a.len());
    for i in 0..a.len() {
        result.push(a[i] + b[i]); // loads a[i], b[i]; stores result[i]
    }
    result
}

```

- **Data Movement**: $2N$ loads + $N$ stores = $3N$ total memory transfers.
- **Sequential Dependency**: Loop-carried dependencies limit parallelisation unless explicitly vectorised (SIMD).
- **Cache Behaviour**: Performance is highly dependent on memory layout; random access or misalignment causes cache misses.
- **Auditability**: Requires external tracing tools to reconstruct the execution path post-mortem.

#### SSCCS Approach

A Scheme defines a set of Segments representing the vectors and an "adder" structure. The compiler, guided by adjacency relations, lays out the Segments consecutively in memory. An observation of the entire structure under a Field that enables addition yields a projection that is the sum vector. This model assumes a hardware environment capable of Near-Data Processing (NDP) or Processing-In-Memory (PIM), where logic is co-located with the data Segments.

```rust
// Rust-like pseudocode
let a = Segment::vector(1..N, initial_value);
let b = Segment::vector(1..N, initial_value);
let scheme = Scheme::add_vectors(a, b);
let field = Field::new();
// Computation is an emergent property of the observation
let sum = observe(scheme, field); 

```

- **Data Movement**: Zero input movement. Segments remain stationary ("Logic-at-Rest"). Only the resulting projection (a single vector of length $N$) is transmitted to the observer.
- **Parallelism**: Structural independence allows all element pairs to be observed concurrently without explicit synchronisation or partitioning.
- **Locality**: Enforced by the compiler’s topological mapping, treating memory as an active topology rather than passive storage.
- **Auditability**: The Scheme serves as an immutable specification of the computational intent; the projection is a deterministic and verifiable consequence.
 
| Aspect | Traditional (Procedural) | SSCCS (Structural) |
| --- | --- | --- |
| Input Data Movement | $2N$ loads | Zero (Stationary Segments) |
| Output Data Movement | $N$ stores | $N$ (Projection) |
| Concurrency | Requires explicit parallelisation | Implicit (Structural independence) |
| Synchronisation | Locks/atomics for shared state | None (Immutability guaranteed) |
| Memory Role | Passive storage | Active topology |
| Auditability | Requires external tracing | Intrinsic to Specification |

This example illustrates the fundamental ontological shift: computation becomes an observation of stationary structure rather than a sequence of data movements. The reduction in data movement is a consequence of this shift, not the primary goal. The deeper benefit lies in the absolute transparency and verifiability that emerge from treating computation as a structural specification.

### 5.5 Scaling to N-Dimensional Tensors and Graphs

The structural principles of SSCCS extend beyond linear vectors to higher-dimensional and non-linear data structures. As dimensionality increases, the inefficiency of the von Neumann bottleneck grows exponentially; SSCCS provides a constant-time logical alternative for structural reorientation.

```{dot}
//| label: fig-scaling  
//| fig-cap: "Scaling SSCCS to N-dimensional tensors and complex graphs"
digraph SSCCS_Scaling {
    rankdir=TB;
    node [shape=plaintext, fontsize=10];

    // Left: Tensor example
    subgraph cluster_tensor {
        label="Tensor (2D Matrix)";
        style=dashed;
        
        // Original matrix as a grid of segments
        node [shape=box, width=0.3, height=0.3, fixedsize=true];
        a11 [label="a11", xlabel="(0,0)"];
        a12 [label="a12", xlabel="(0,1)"];
        a21 [label="a21", xlabel="(1,0)"];
        a22 [label="a22", xlabel="(1,1)"];
        
        // Grid arrangement
        { rank=same; a11; a12; }
        { rank=same; a21; a22; }
        edge [style=invis];
        a11 -> a12;
        a21 -> a22;
        a11 -> a21;
        a12 -> a22;
        
        // Field reorientation
        reshape [shape=plaintext, label="Field reorients\nobservation path", fontsize=8];
        edge [style=dashed];
        a11 -> reshape;
        a12 -> reshape;
        a21 -> reshape;
        a22 -> reshape;
        
        // Transposed view (projection)
        node [shape=box, width=0.3, height=0.3];
        t11 [label="a11", xlabel="(0,0)"];
        t12 [label="a21", xlabel="(0,1)"];
        t21 [label="a12", xlabel="(1,0)"];
        t22 [label="a22", xlabel="(1,1)"];
        
        { rank=same; t11; t12; }
        { rank=same; t21; t22; }
        edge [style=invis];
        t11 -> t12;
        t21 -> t22;
        t11 -> t21;
        t12 -> t22;
        
        note_tensor [shape=plaintext, label="No data moved;\nonly projection view changes", fontsize=8];
    }

    // Right: Graph example
    subgraph cluster_graph {
        label="Graph (Nodes as Segments)";
        style=dashed;
        
        node [shape=circle, width=0.3, height=0.3, fixedsize=true];
        n1 [label="1"];
        n2 [label="2"];
        n3 [label="3"];
        n4 [label="4"];
        
        // Edges are structural constraints
        edge [arrowhead=none, style=solid];
        n1 -> n2;
        n1 -> n3;
        n2 -> n3;
        n3 -> n4;
        
        // Field propagates across graph
        field_label [shape=plaintext, label="Field propagates\nin one observation", fontsize=8];
        edge [style=dashed, color=gray];
        n1 -> field_label [style=invis];
        n2 -> field_label [style=invis];
        n3 -> field_label [style=invis];
        n4 -> field_label [style=invis];
        
        // Resulting emergent state (projection)
        node [shape=box, fontsize=8];
        proj1 [label="new state 1"];
        proj2 [label="new state 2"];
        proj3 [label="new state 3"];
        proj4 [label="new state 4"];
        
        edge [arrowhead=normal, style=solid, color=black];
        n1 -> proj1;
        n2 -> proj2;
        n3 -> proj3;
        n4 -> proj4;
        
        note_graph [shape=plaintext, label="All nodes observed\nsimultaneously;\nno locks or iterators", fontsize=8];
    }

    // Align the top nodes of both clusters horizontally
    { rank=same; a11; n1; }
    // Invisible edge to ensure they stay on same row (optional, but helps)
    a11 -> n1 [style=invis];
}
```

#### 5.5.1 N-Dimensional Tensors

In SSCCS, an $N$-dimensional tensor is represented as a set of Segments where adjacency relations are defined across multiple axes within the Scheme.

- **Zero-Copy Reshaping**: Traditional systems require physical data movement ($O(N)$ or $O(N^2)$) to perform operations like transposition or reshaping. In SSCCS, reshaping is a metadata-only operation. By reorienting the Field’s observation path over stationary Segments, the dimensionality of the Projection changes without moving a single bit in memory ($O(1)$).
- **Logical Adjacency**: For operations like matrix multiplication, the compiler maps Segments to ensure that the required operands for a specific Field are physically co-located. This transforms what would be complex indexing logic in a CPU into a direct physical property of the memory topology.

#### 5.5.2 Complex Graph Processing

Graph algorithms (e.g., PageRank, GNNs) are traditionally bottlenecked by "Pointer Chasing," which causes severe cache thrashing and memory latency.

- **Segment-as-Node**: Each node and its properties are encapsulated in a Segment.
- **Adjacency-as-Structure**: Edges are defined as structural constraints within the Scheme, not as memory pointers to be followed sequentially.
- **Field-based Traversal**: A Field propagates across the entire Scheme in a single observation cycle. Instead of "visiting" nodes, the observer captures the emergent state of the entire graph simultaneously.
- **Concurrency**: This eliminates vertex-centric synchronization (locks/mutexes). All nodes update their state in parallel as a deterministic consequence of the Field's interaction with the Scheme's topology.

### Comparison: Computational Density at Scale

| Computational Task | Traditional Bottleneck | SSCCS Solution |
| --- | --- | --- |
| Tensor Reshaping | Physical data reshuffling ($O(N^d)$) | Metadata-level Field reorientation ($O(1)$) |
| Matrix Contraction | Memory bandwidth & indexing overhead | Hardwired adjacency in the Scheme |
| Graph Traversal | High latency due to random access | Distributed parallel observation |
| Sparse Operations | Complex indexing & storage overhead | Non-linear Scheme mapping (skipping null-space) |

The scaling of SSCCS addresses the Curse of Dimensionality by decoupling the logical structure of data from the physical cost of its traversal. While traditional architectures expend energy moving data to accommodate logic, SSCCS modifies the Field to accommodate the stationary structure. This positions SSCCS as a foundational methodology for future AI-hardware co-design, where computational density and energy efficiency are the primary constraints.
 
## 6. The Open Format

A central goal of SSCCS is the definition of an open `.ss` format—a human‑readable, machine‑processable representation of Segments and Schemes. The format is designed to be language‑agnostic and platform‑independent. (If desired: “The specification is currently under development; once the Segment‑Scheme structure is finalized, a translation layer may convert existing data representations into `.ss`.”)

Characteristics:
- Human‑readable, machine‑processable.
- Immutable by default; evolution creates new versions.
- Cryptographically identifiable (hash‑based).
- Compositional: Schemes can include other Schemes.
- Platform‑independent.

### 6.1 Binary Serialization and Memory Layout

The binary encoding of a Scheme includes:
- Header (SchemeId, version)
- Axes list (definitions of each axis)
- Segment table (IDs, coordinate ranges, and associated data)
- Relation graph (encoding of adjacency, hierarchy, and dependencies)
- Serialized `MemoryLayout` (layout type, encoded mapping function, metadata)
- Observation rules and constraints

This binary format ensures interoperability across implementations and enables deterministic reconstruction of the Scheme’s structure.
 
## 7. System Stack and Instruction‑Set Interaction

SSCCS inserts a runtime layer between application and hardware that translates observation requests into hardware‑specific memory mappings and observation primitives. The runtime coordinates the Scheme interpreter and projector to realise observation without moving data unnecessarily.

```{dot}
//| label: fig-system-stack
//| fig-cap: "SSCCS system stack"
digraph SystemStack {
    rankdir=TB;
    node [shape=rect, style=rounded];
    CPU [label="CPU / ISA"];
    RAM [label="RAM / Cache"];
    PIM [label="PIM Unit\n(optional)"];
    Runtime [label="SSCCS Runtime\n(Observation Manager)"];
    SchemeInterpreter [label="Scheme Interpreter\n(MemoryLayout resolver)"];
    Projector [label="Projector\n(Ω)"];
    App [label="Application"];
    App -> Runtime [label="observe(scheme, field)"];
    Runtime -> SchemeInterpreter [label="resolve layout"];
    SchemeInterpreter -> CPU [label="logical‑to‑physical mapping", style=dashed];
    SchemeInterpreter -> RAM [label="logical‑address lookup"];
    Runtime -> Projector [label="execute Ω"];
    Projector -> CPU [label="observation micro‑ops", style=dashed];
    Projector -> PIM [label="in‑memory observation", style=dashed];
    CPU -> RAM [label="load/store (minimal)"];
    PIM -> RAM [label="direct access"];
}
```

In environments without direct hardware support, a lightweight software runtime emulates the observation process by interpreting the binary `.ss` format.


### 7.1. Hardware Considerations  

While SSCCS can be implemented in software, its benefits are most pronounced with hardware support:

- No instruction fetch unit; observation triggered structurally.
- Processing‑in‑memory (PIM) for direct observation.
- Spatial computation mapping adjacency to wiring.
- Cryptographic primitives in hardware.
 
## 8. Theoretical Performance & Scalability

The SSCCS architecture derives its efficiency not from incremental hardware acceleration, but from a fundamental shift in computational complexity. By redefining execution as the Structural Observation of a stationary Scheme, the framework bypasses the sequential bottlenecks inherent in the von Neumann architecture.

### 8.1 Architectural Expectations of Time-Space Complexity

Traditional procedural models are constrained by the linear relationship between data volume ($N$) and execution cycles. SSCCS decouples this relationship by utilizing the concurrent propagation of a Field across a pre-defined Topology.

```{python}
#| label: fig-complexity
#| fig-cap: "Asymptotic Complexity: Procedural vs. SSCCS Structural Observation"

import matplotlib.pyplot as plt
import numpy as np

# Define Data Scale (N)
N = np.geomspace(1, 1024, 100)

# 1. Temporal Complexity (Latency)
# Procedural: O(N)
# SSCCS: O(log N) - Field Propagation
latency_procedural = N * 1.2 + 5
latency_ssccs = np.log2(N) + 2

# 2. Data Movement Complexity (Energy/Space)
# Procedural: O(N*D)
# SSCCS: O(Output) - Logic-at-Rest
movement_procedural = N**1.15
movement_ssccs = np.ones_like(N) * 10 + (N * 0.1)

# Plotting with Fixes for Matplotlib 3.x+
fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 5))

# Latency Plot - Using Raw Strings for LaTeX labels
ax1.plot(N, latency_procedural, color='gray', linestyle='--', label=r'Procedural: $O(N)$')
ax1.plot(N, latency_ssccs, color='gray', linewidth=2, label=r'SSCCS: $O(\log N)$')
ax1.set_xscale('log')
ax1.set_yscale('log')
ax1.set_title('Execution Latency (Time)', fontweight='bold')
ax1.set_xlabel(r'Scale of Data ($N$)')
ax1.set_ylabel('Cycles (Log Scale)')
ax1.legend()

# Data Movement Plot
ax2.plot(N, movement_procedural, color='gray', linestyle='--', label=r'Procedural: $O(N \cdot D)$')
ax2.plot(N, movement_ssccs, color='black', linewidth=2, label=r'SSCCS: $O(Projection)$')
ax2.set_xscale('log')
ax2.set_yscale('log')
ax2.set_title('Data Movement (Energy/Space)', fontweight='bold')
ax2.set_xlabel(r'Scale of Data ($N$)')
ax2.set_ylabel('Transfer Volume (Log Scale)')
ax2.legend()

plt.tight_layout()
plt.show()
```

#### 8.1.1 Temporal Complexity (Latency)

In a von Neumann environment, even with SIMD/MIMD parallelism, latency scales at $O(N)$ or $O(N/k)$ due to instruction dispatch, synchronization, and memory-wall stalls.

- **SSCCS Latency**: Defined by the physical propagation delay of the Field across the Scheme. Because structural constraints are resolved at the mapping phase, the observation of the result—the Projection—approaches $O(\log N)$ or even $O(1)$ in specialized hardware environments such as Processing-In-Memory (PIM).

#### 8.1.2 Data Movement Complexity (Spatial/Energy Cost)

The primary energy sink in modern computing is the movement of operands from memory to logic units.

- **Procedural Cost**: $O(N \cdot D)$, where $D$ represents the dimensionality of the data required for each operation.
- **SSCCS Cost (Logic-at-Rest)**: $O(Projection)$. Since the input Segments remain stationary within the Scheme, the energy expenditure is strictly limited to the transmission of the resulting Projection. This creates a widening efficiency gap as the scale of $N$ increases.

### 8.2 Comparative Complexity Matrix

The following table summarizes the asymptotic behavior of SSCCS compared to traditional sequential and parallel (SIMD) architectures.

| Metric | Sequential | Parallel (SIMD/GPU) | SSCCS (Structural) |
| --- | --- | --- | --- |
| Instruction Overhead | High ($O(N)$) | Moderate ($O(N/k)$) | Minimal (Field-based) |
| Data Locality | Managed (Cache) | Explicit (SRAM/Tiling) | Intrinsic (Scheme-defined) |
| Execution Latency | $O(N)$ | $O(N/k) + \text{sync}$ | $O(\log N)$ or $O(1)$ |
| Data Movement | $O(N)$ | $O(N)$ | $O(\text{Output Only})$ |
| Scalability Limit | Amdahl's Law | Memory Bandwidth | Physical Propagation Delay |

### 8.3 Scalability in High-Dimensional AI Workloads

As demonstrated in the emergence of State-Space Models (SSMs) $[6]$ and manifold-constrained learning $[5]$, the ability to process high-dimensional representations without exhaustive data shuffling is critical.

1. Stationary Topology: By fixing the Segments in a k-dimensional `MemoryLayout`, SSCCS allows the hardware to perform "Observation" as a near-instantaneous mapping.
2. Implicit Parallelism: Unlike threads or warps that require explicit management, SSCCS parallelism is implicit—it is a property of the structure itself. The scalability is limited only by the fidelity of the Field and the resolution of the Projector ($\Omega$).


## 9. Implementation Roadmap  

```{dot}
//| label: fig-roadmap
//| fig-cap: "Implementation roadmap: three research phases"
digraph Implementation_Roadmap {
    rankdir=LR;
    node [shape=rect];
    Phase1 [label="Phase 1\nSoftware Emulation\n(Reference in Rust)"];
    Phase2 [label="Phase 2\nHardware Acceleration\n(FPGA / PIM)"];
    Phase3 [label="Phase 3\nNative Observation-Centric Processors"];
    Phase1 -> Phase2 [label="Validate"];
    Phase2 -> Phase3 [label="Scale"];
    subgraph cluster_goals {
        label="Goals";
        G1 [label="Structural Fidelity"];
        G2 [label="Parallelism"];
        G3 [label="Energy Efficiency"];
    }
    Phase1 -> G1;
    Phase2 -> G2;
    Phase3 -> G3;
}
```

### Phase 1: Software Emulation (Proof of Concept)
- Rust reference implementation reading `.ss` specifications.
- Validate model on small benchmarks (matrix multiplication, graph algorithms).
- Measure determinism, implicit parallelism, data movement reduction.
- Establish toolchain and community.

### Phase 2: Hardware Acceleration
- Map Schemes to FPGA fabrics.
- Explore PIM architectures (UPMEM, Samsung FIM).
- Develop compiler targeting CPUs (via SIMD) and FPGA/PIM.
- Begin formal verification.

### Phase 3: Native Observation‑Centric Processors (Long‑Term Research)
- Design processor directly instantiating Schemes.
- Integrate memory and logic in unified substrate (e.g., memristor arrays).
- Evaluate energy efficiency for target domains.
- Establish SSCCS as foundational infrastructure.

Throughout, the `.ss` blueprint remains unchanged, preserving investment.

## 10. Planned Validation Domains  

SSCCS is intended for validation across multiple domains. The following table outlines traditional challenges and expected advantages:

| Domain               | Traditional Challenge                                     | Expected Advantages              |
|----------------------|-----------------------------------------------------------|------------------------------------------------------|
| Climate modelling    | Massive state space, grid data movement                   | Constraint isolation, deterministic observation, minimal data transfer |
| Space systems        | Radiation-induced errors, power constraints               | Structural reproducibility, error detectability, verifiable execution |
| Protein folding      | Combinatorial explosion, long time scales                  | Massive parallel observation, structure-guided exploration |
| Swarm robotics       | Coordination overhead, limited communication              | Recursive composition, emergent coordination from shared structure |
| Financial modelling  | Real‑time constraints, complex dependencies                | Deterministic projections, no race conditions, auditable processing |
| Cryptographic systems| Side‑channel attacks, verification complexity              | Immutable structure enables formal verification, no intermediate state |
| Autonomous vehicles  | Sensor fusion, real‑time decision making                   | Constraint‑based observation, deterministic response, auditable decisions |
 
## 11. Related Work  

SSCCS is presented alongside several established research domains, providing a unified theoretical foundation:

- Dataflow architectures (e.g., Dennis's dataflow graphs) treat programs as graphs where nodes fire when inputs are available.
- Functional programming emphasises immutability and referential transparency.
- Processing‑in‑memory (PIM) research directly addresses the data movement problem.
- Declarative languages (SQL, Datalog) describe *what* to compute rather than how.
- Intentional programming and memoisation share conceptual ground with observation‑based computation.

Recent work in AI demonstrates the growing relevance of structural constraints:

- **Geometric Constraints**: Research such as *Manifold-Constrained Hyper-Connections* by DeepSeek $[5]$ highlights the efficacy of applying geometric inductive biases in high-dimensional representations. This validates the SSCCS approach of defining computational processes through topological constraints rather than procedural instructions.

- **SSCCS as a Structural Superset**: SSCCS serves as a formal ontological superset for State-Space Models (SSMs) like Mamba $[6]$ and hardware-aware frameworks such as Modular AI's MAX/Mojo $[7, 8]$. While these systems achieve high-performance linear recurrences through ad-hoc kernel tuning, SSCCS redefines the SSM recurrence not as a procedural loop, but as a one-dimensional Scheme of adjacent Segments where state transitions emerge as Projections of a sequential Field. By shifting from execution-based optimization to the deterministic observation of stationary topological constraints, SSCCS inherently encompasses the efficiency gains of modern AI execution engines within a universal, structure-defined architecture.


These references contextualize SSCCS within the broader intellectual landscape. In each domain, the shift from execution to observation is expected to offer advantages that incremental optimization cannot provide. These advantages—determinism, parallelism, fault isolation, reduced communication, and above all verifiability—are expected consequences of the ontological redefinition, not features added to address specific problems.

## 12. Conclusion and Future Work  

This paper has presented SSCCS, a computational model that redefines computation as the observation of structured potential under dynamic constraints. The model's core components—immutable Segments, geometric Schemes, mutable Fields, and the Observation/Projection mechanism—constitute a new computational ontology. From this ontology, multiple consequences follow: elimination of most data transfers, removal of synchronization overhead, implicit parallelism, deterministic reproducibility, and secure isolation within cryptographically enforced boundaries.

Observation deterministically resolves admissible configurations from the combination of Scheme and Field into a Projection, without altering underlying Segments. The compiler performs structural mapping, and the open `.ss` format ensures platform‑independent, verifiable specifications.

Planned validation across multiple domains—climate modeling, space systems, protein folding, swarm robotics, financial modeling, cryptographic systems, and autonomous vehicles—will assess the model's advantages: determinism, parallelism, fault isolation, reduced communication, and verifiability.

In summary, SSCCS establishes several foundational principles:

- Computation concerns revelation rather than change.
- Structure is more fundamental than process.
- Time is a coordinate rather than a flow.
- Value is projected rather than intrinsic.
- Programs are blueprints rather than recipes.
- Results are configurations revealed by Observation.
- Composition is the primitive of computation.
- Structure serves as executable law.
- Observation is the sole active event.
- Projection is the deterministic outcome of Observation.
- Immutability provides the foundation for concurrency and security.

The model is not presented as a complete replacement for all computing, but as a promising direction for data-intensive, parallel workloads where the limitations of the von Neumann model are most apparent. More importantly, it offers a way of thinking about computation that may prove fruitful beyond its immediate engineering applications—a framework that prioritizes verifiability and accessibility over opaque procedural execution. 

## References  

- [1] W. A. Wulf and S. A. McKee, "Hitting the memory wall: implications of the obvious," *ACM SIGARCH Computer Architecture News*, vol. 23, no. 1, pp. 20–24, 1995.
- [2] S. Borkar and A. A. Chien, "The future of microprocessors," *Communications of the ACM*, vol. 54, no. 5, pp. 67–77, 2011.
- [3] R. Lucas et al., "Top ten exascale research challenges," US Department of Energy, 2014.
- [4] M. Horowitz, "Computing's energy problem (and what we can do about it)," in *IEEE International Solid‑State Circuits Conference*, 2014.
- [5] DeepSeek-AI, "Manifold-Constrained Hyper-Connections: Geometric Inductive Biases in High-Dimensional Representations," *arXiv preprint arXiv:2512.24880*, 2025.
- [6] A. Gu and T. Dao, "Mamba: Linear-Time Sequence Modeling with Selective State Spaces," *arXiv preprint arXiv:2312.00752*, 2023.
- [7] Modular AI, "MAX: A Unified AI Execution Engine," [Online]. Available: https://www.modular.com/max. Accessed Feb. 2026.
- [8] C. Lattner et al., "Mojo: Programming Language for All of AI," [Online]. Available: https://www.modular.com/mojo. Accessed Feb. 2026.

---

© 2026 SSCCS gUG (i.G.) — A non‑profit research initiative, formalized through global standards and its authenticity substantiated by immutable scientific records and cryptographic proofs.

- Source code under Apache 2.0: [Github](https://github.com/ssccsorg) | GPG ID: [BCCB196BADF50C99](https://keys.openpgp.org/search?q=BCCB196BADF50C99)
- Whitepaper under CC BY-NC-ND 4.0: [PDF](https://ssccs.org/wp) [HTML](https://ssccsorg.github.io/ssccs) | Registered DOI: [10.5281/zenodo.18787286](https://doi.org/10.5281/zenodo.18787286) by CERN, [OpenAIRE](https://explore.openaire.eu/search/result?pid=10.5281%2Fzenodo.18787286)

::: {.content-visible when-format="pdf"}
```{python}
#| echo: false
#| results: asis
#| include: true
import os, tempfile
svgs = [
'''
<svg xmlns="http://www.w3.org/2000/svg" width="183" height="68" viewBox="419.948 119.623 183 68">
    <path d="M494.438 150.589c-4.14 0-6.459 3.229-6.459 6.897 0 3.666 2.307 6.895 6.459 6.895 4.152 0 6.459-3.242 6.459-6.895 0-3.655-2.331-6.897-6.459-6.897m0 16.111a8.91 8.91 0 0 1-9.045-9.214c-.002-4.996 4.045-9.048 9.04-9.05 4.995-.002 9.047 4.045 9.05 9.039v.011a8.91 8.91 0 0 1-8.602 9.209c-.147.005-.295.007-.443.005M511.374 156.526a3.776 3.776 0 0 0-3.649 3.898l.007.133a3.774 3.774 0 0 0 3.642 4.03c2.173 0 3.642-1.627 3.642-4.03 0-2.404-1.469-3.958-3.618-3.958Zm.51 10.174a4.857 4.857 0 0 1-4.116-2.319v5.949a1.214 1.214 0 1 1-2.428 0v-14.569a1.215 1.215 0 0 1 1.069-1.214h.048c.671 0 1.214.544 1.214 1.214v1.008a4.857 4.857 0 0 1 4.189-2.295 5.767 5.767 0 0 1 5.59 5.938l-.006.132c.024 3.715-2.489 6.156-5.56 6.156M524.473 156.465a3.339 3.339 0 0 0-3.351 2.962h6.58a3.241 3.241 0 0 0-3.229-2.962m5.585 4.141c0 .436-.243.85-.96.85h-8.073a3.351 3.351 0 0 0 3.642 3.241 4.119 4.119 0 0 0 3.108-1.311 1.31 1.31 0 0 1 .838-.402 1.021 1.021 0 0 1 1.044.984c-.027.268-.142.52-.328.716a6.362 6.362 0 0 1-4.759 1.955 5.78 5.78 0 0 1-6.07-6.071 5.914 5.914 0 0 1 5.67-6.07h.315c3.351-.035 5.573 2.683 5.573 6.108M537.075 154.462a5.487 5.487 0 0 1 5.609 5.363v5.503a1.25 1.25 0 0 1-2.501 0v-5.573a3.096 3.096 0 0 0-6.18 0v5.573a1.256 1.256 0 1 1-2.513 0v-5.281a5.464 5.464 0 0 1 5.318-5.585M553.234 152.811l-2.78 6.774h5.56Zm3.957 9.639h-7.916l-1.541 3.266c-.232.542-.77.887-1.359.874a1.518 1.518 0 0 1-1.543-1.493c.004-.22.057-.436.159-.631l6.847-15.2c.23-.557.794-.901 1.396-.85a1.348 1.348 0 0 1 1.384.85l6.846 15.2c.1.195.154.411.159.631a1.518 1.518 0 0 1-1.505 1.53 1.411 1.411 0 0 1-1.361-.874M564.463 166.59a1.663 1.663 0 0 1-1.65-1.651v-14.921a1.64 1.64 0 0 1 1.638-1.639l.012.002a1.6 1.6 0 0 1 1.603 1.601V164.939a1.615 1.615 0 0 1-1.578 1.651h-.013M577.951 151.585h-5.694v4.856h5.694a2.429 2.429 0 0 0 2.562-2.27 1.485 1.485 0 0 0 0-.231 2.357 2.357 0 0 0-2.598-2.367Zm5.888 13.354c0 .896-.719 1.626-1.615 1.639a1.48 1.48 0 0 1-1.444-.886l-3.12-6.398h-5.403v5.645a1.626 1.626 0 1 1-3.253 0V150.25a1.626 1.626 0 0 1 1.602-1.639h6.896c4.431 0 6.337 2.197 6.337 5.353a4.855 4.855 0 0 1-2.95 4.747l2.756 5.585c.106.2.172.418.194.643M597.764 166.384h-9.967a1.65 1.65 0 0 1-1.651-1.627V150.25c0-.906.733-1.639 1.639-1.639h9.627a1.505 1.505 0 0 1 1.542 1.456 1.518 1.518 0 0 1-1.506 1.53H589.411v4.249h6.775c.84 0 1.523.678 1.529 1.518a1.517 1.517 0 0 1-1.517 1.505h-6.787v4.456h8.402a1.517 1.517 0 0 1 1.554 1.505c0 .831-.674 1.505-1.506 1.505M470.74 153.564c-.619 0-1.214 0-1.857-.097.204 1.121.306 2.259.303 3.399 0 10.56-8.561 19.121-19.121 19.121-10.56 0-19.121-8.561-19.121-19.121 0-10.56 8.561-19.121 19.121-19.121h.012c1.181 0 2.36.11 3.521.328a16.727 16.727 0 0 1-.085-1.748 17.329 17.329 0 0 1 1.214-6.459c-14.903-2.588-29.083 7.395-31.671 22.299-2.588 14.903 7.395 29.082 22.299 31.67 14.903 2.589 29.082-7.395 31.67-22.298.268-1.543.403-3.105.404-4.671a27.994 27.994 0 0 0-.364-4.516 17.25 17.25 0 0 1-6.325 1.214m5.451-15.88h-3.994v3.995a1.469 1.469 0 0 1-2.926.17v-4.189h-3.994a1.323 1.323 0 1 1 0-2.646h4.018v-3.995a1.47 1.47 0 0 1 2.926 0v3.995h3.994a1.323 1.323 0 1 1 0 2.646Zm9.409-2.852c-.05-.498-.127-.993-.231-1.482a13.837 13.837 0 0 0-.364-1.432 15.316 15.316 0 0 0-.364-1.044 14.93 14.93 0 0 0-.437-.984 11.406 11.406 0 0 0-.814-1.42c-.085-.158-.194-.304-.291-.449a15.154 15.154 0 0 0-1.821-2.222 14.81 14.81 0 0 0-4.711-3.193c-.388-.17-.789-.315-1.214-.449a14.979 14.979 0 0 0-4.613-.765h-.704a2.878 2.878 0 0 0-.656 0c-.33.015-.659.056-.983.122l-.571.109h-.073l-.522.121-.279.122c-.201.045-.4.102-.595.17l-.679.23-.498.158-.377.182-.522.219c-.162.071-.32.152-.473.243l-.376.194-.377.218a8.107 8.107 0 0 0-.777.522c-.255.195-.34.243-.51.365-.134.09-.264.187-.388.291l-.255.206-.595.522-.388.377a5.23 5.23 0 0 0-.353.376l-.194.206-.352.401-.303.389a2.967 2.967 0 0 0-.243.315 7.3 7.3 0 0 0-.352.486c-.11.17-.255.388-.377.595-.12.183-.229.374-.327.57a.474.474 0 0 0-.061.11l-.34.679-.243.522a15.026 15.026 0 0 0-1.214 5.961c0 .789.061 1.576.182 2.356 0 .267.097.509.158.801.061.291.085.388.134.57a14.676 14.676 0 0 0 .716 2.089c.097.218.194.437.303.655l.328.656c.109.218.292.51.449.777.158.267.522.752.765 1.104.279.353.559.705.862 1.032.165.183.339.358.522.522.179.161.349.331.51.51l.522.474a13.196 13.196 0 0 0 2.428 1.602c.208.122.423.231.644.328.327.17.667.316.995.449l1.032.352.522.158.522.134.546.121a15.02 15.02 0 0 0 8.693-.935c.453-.194.895-.413 1.323-.655.188-.096.37-.201.547-.316.241-.132.472-.282.692-.449a3.22 3.22 0 0 0 .412-.291l.389-.292.303-.243a4.19 4.19 0 0 0 .401-.352l.291-.267c.434-.375.84-.78 1.214-1.214l.267-.328c.041-.045.077-.094.11-.145.099-.121.193-.246.279-.377.46-.62.866-1.278 1.214-1.966.133-.243.255-.522.364-.765v-.085c.078-.166.147-.336.207-.51.06-.194.121-.34.182-.522.06-.182.218-.656.315-.984v-.084a3.51 3.51 0 0 0 .097-.389c.026-.088.047-.177.061-.267a1.62 1.62 0 0 1 .073-.352v-.134c0-.279.097-.582.133-.874a.614.614 0 0 0 0-.218 1.221 1.221 0 0 1 0-.352c.015-.19.015-.381 0-.571v-.716c.073-.595.11-1.093.11-1.578" fill="currentColor"/>
</svg>
''',
'''
<svg version="1.1" id="svg3759" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:rdf="http://www.w3.org/1999/02/22-rdf-syntax-ns#" xmlns:cc="http://creativecommons.org/ns#" xmlns:svg="http://www.w3.org/2000/svg" xmlns:sodipodi="http://sodipodi.sourceforge.net/DTD/sodipodi-0.dtd" xmlns:inkscape="http://www.inkscape.org/namespaces/inkscape" sodipodi:docname="logoCERN.svg" inkscape:version="0.92.1 r15371" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" x="0px" y="0px" viewBox="618.3 -198.9 383.5 380.1" style="enable-background:new 618.3 -198.9 383.5 380.1;" xml:space="preserve"><sodipodi:namedview inkscape:cy="560" showgrid="false" inkscape:cx="-127.14286" inkscape:zoom="0.35" borderopacity="1.0" pagecolor="#ffffff" bordercolor="#666666" id="base" inkscape:window-maximized="1" inkscape:window-y="-8" inkscape:current-layer="layer1" inkscape:pageshadow="2" inkscape:document-units="mm" inkscape:pageopacity="0.0" inkscape:window-height="1027" inkscape:window-x="1912" inkscape:window-width="1920"></sodipodi:namedview><g id="layer1" inkscape:label="Capa 1" inkscape:groupmode="layer"><path id="path3704" sodipodi:nodetypes="csccssscscscccsscscccsscsscccscssssscssccscsccccsccccscccsscssscscsccccccsccscsscccccscsccccsssccscccscccsscsccscccccccccccccccccscsscsccccscccccccccccccccccccccccccccccccscccccccscccccccscccccc" inkscape:connector-curvature="0" class="st0" d="M713.8,175.5c3.1-3.2,26.6-28.2,52.4-55.8s50-53.3,53.9-57.3l7.1-7.3l-10.5,5.5c-19.7,10.3-33.1,13.6-57.6,14.4c-20,0.6-30.9-0.8-47.1-6.2C683,59,659.2,41.2,643,16.9c-2.9-4.3-5.3-7.6-5.3-7.4c0,0.3,21.8,74.4,25.6,86.9c0.4,1.4-0.1,1.7-3.1,1.7c-3,0-3.8-0.5-4.6-2.7c-3.2-8.4-31.3-109.4-34.1-122.4c-3-14.2-3.3-20.8-3.3-33.9c0-7.4,0.4-20.4,1.8-26.8c5-22.6,14.7-43.1,29.1-60.8c19.6-24.4,48.3-41.7,79.6-48c7.7-1.6,20.5-1.8,140.7-2.1l132.3-0.4v3v3l-26.8,0c-14.7,0-60.9,0.3-102.7,0.7c-75.5,0.7-75.9,0.7-70.5,2.5c8.3,2.8,24.9,11.3,32.6,16.7c7.4,5.2,17.7,14.1,17.1,14.8c-0.2,0.2-3.2-0.3-6.6-1.2c-4.4-1.1-8.5-3.3-14.4-7.5c-33.1-23.9-76.7-30.7-115.4-18c-19.8,6.5-35.9,16.5-51.4,32c-25.5,25.5-38.2,55.7-38.2,91.1c0,21.1,3.5,36.8,12.4,55.9c12.6,27,37.6,51.3,65.1,63.2c29.2,12.8,62.5,14.3,92.5,4.4c20.5-6.8,34.7-15.7,51-31.9c15.9-15.9,25.3-30.9,31.8-51c5-15.5,6-22.3,6-40.6c0-14.5-0.4-17.8-2.7-27.1c-4.3-17.2-10.2-30.7-19-43.8c-5.4-8-5.1-8.3,3.7-3.9c4.9,2.5,5.3,3,11.4,14.7c10.3,20,14.3,33.7,28,96.5c9.3,42.4,44.8,201.7,45.7,204.8c0.4,1.5-0.2,1.7-3.5,1.7c-3.9,0-4,0-5-4.8c-14.5-68-50.8-229.8-51.3-228.5c-0.4,1-0.7,3.8-0.8,6.4C890.5-28.3,881.7-4,868,16.7c-9.8,14.8-20.4,26.8-86.5,97.2l-63.2,67.3h-5h-5L713.8,175.5z M805.7,120.6c-9.5-1-19.8-2.6-20.8-3.3c-0.8-0.5-0.3-1.6,1.7-3.5l2.9-2.8l9.1,1.2c11,1.5,30.4,0.8,41.1-1.5c25.7-5.5,48.1-17.5,66.2-35.7c4.8-4.8,8.9-8.4,9.1-8.1c0.2,0.4,0.7,2.3,1,4.3c0.8,4.5-0.5,6.2-11.6,15.6c-19.9,16.8-39.5,26.4-63.3,31.2C831.5,120,812.7,121.4,805.7,120.6L805.7,120.6z M756.7,107.6c-13.8-6.7-28.2-16.6-38.4-26.5l-9-8.7l7.7,2.2c5.8,1.7,8.7,3.2,12,6.2c9.9,9.1,25.9,18.8,38.7,23.5l6.2,2.3l-2.7,2.9c-1.5,1.6-3.2,2.9-3.9,2.9C766.6,112.2,761.8,110.2,756.7,107.6L756.7,107.6z M927,54.7c-1-4.3-0.8-4.9,3.6-13.8c9.9-19.7,13.6-35.6,13.5-58.2c0-22.2-4-40.4-13.1-60.4c-13.3-29.1-41-54.7-71.1-65.5c-48.7-17.5-98-7.1-136.1,28.8l-7.1,6.7l-2.5-1.8c-1.4-1-2.5-2.3-2.5-2.8c-0.1-1.7,14.7-15.1,23.8-21.5c9.9-7.1,25.1-14.7,36.4-18.4c14.6-4.7,23.8-6,42.7-6c25.5,0.1,40.8,3.7,62.5,14.7c18.8,9.6,38.3,26.6,49.5,43.1c10.6,15.7,19.7,38,22.4,54.7l1.3,8.4l0.7-5c0.8-5.9,11.7-118.5,11.7-120.8c0-1.2,0.9-1.7,3.5-1.7c3.2,0,3.5,0.3,3.5,2.8c0,3.4-9.2,95.5-12.1,120.6c-4.2,36.9-9.1,59.8-16.8,77.5c-3.4,7.8-11.6,23.1-12.5,23.1C928.2,59.2,927.6,57.2,927,54.7L927,54.7z M699,50.7c-4.4-2.1-5.6-3.2-8.1-8.2c-6.7-13.2-12.1-33.2-13.6-50.1l-0.7-7.3h4.1h4.1v4.9c0,7.1,3.6,24.8,7.1,34.9c1.7,4.8,5.3,12.9,8,18.1c2.7,5.2,4.8,9.5,4.6,9.7C704.3,53,701.8,52.1,699,50.7z M667.2-37.5c-11.1-4-17.1-12-18.1-24.1c-1.1-13.1,3.9-22.5,15-28.1c6.5-3.3,7.4-3.5,16-3.4c5,0.1,11.2,0.8,13.6,1.6c4.3,1.3,4.5,1.6,4.2,4.8c-0.4,4.5-0.8,4.7-3.5,2.2c-5.3-5-16.2-6.6-23.2-3.3c-8.8,4.1-13.8,12.4-13.7,23.1c0,10.7,4.7,18.5,13.7,22.6c8.1,3.8,16.5,2.7,24.1-3.1l3.6-2.7l-0.3,3.3c-0.3,2.8-1.1,3.7-4.8,5.8C687.7-35.5,674.6-34.9,667.2-37.5z M846.2-39c-4.3-5.1-35.8-38.2-36.8-38.6c-0.6-0.2-0.7,7.6-0.2,20.2l0.7,20.6h-3.7c-3.6,0-3.7-0.1-3.1-3.1c0.3-1.7,0.6-14.3,0.6-28c0-20.7,0.2-24.9,1.4-24.9c0.8,0,10.1,9,20.6,20c10.6,11,19.7,20,20.2,20c0.6,0,0.7-7,0.3-19.7l-0.7-19.8l3.7-0.1c3.6-0.1,3.7,0,3.1,2.9c-0.3,1.6-0.6,14.4-0.6,28.3C851.7-33.3,851.5-32.6,846.2-39L846.2-39z M708.7-64.5v-27.7h16.5h16.5v2.7v2.7l-12.5-0.6l-12.5-0.6v10.3v10.3l10-0.4l10-0.4v2.9v2.9l-10-0.4l-10-0.4v10.9v10.9l13-0.6l13-0.6v2.9v2.9h-17h-17L708.7-64.5z M753.2-64.5v-27.7l13.5,0.1c15.1,0.1,18.8,1.2,21.5,6.4c2.1,4,1.9,9.9-0.4,13.5c-2.1,3.2-8.6,7.5-11.2,7.6c-0.9,0-1.9,0.4-2.2,0.9c-0.3,0.5,4.4,6.8,10.5,14l11,13.2l-5.3,0l-5.3,0l-4.5-6.7c-9.3-13.7-14.9-20.3-17.7-20.3h-2.6l0.7,13.5l0.7,13.5l-4.4,0l-4.4,0L753.2-64.5z M772.3-67.9c9-2.3,12.2-10.7,6.5-17.1c-2.6-2.9-3.5-3.3-9.9-3.6l-7-0.4l-0.7,10c-0.4,5.5-0.4,10.5-0.1,11.1C762-66.5,766.7-66.5,772.3-67.9L772.3-67.9z"/></g></svg>
'''
]
for i, svg in enumerate(svgs):
    os.makedirs("Whitepaper_files", exist_ok=True)
    with open(f"./Whitepaper_files/image{i}.svg", "w", encoding="utf-8") as f:
        f.write(svg)
```

```{=latex}
\begin{flushright}
    \includesvg[height=30pt]{./Whitepaper_files/image0.svg}
    \hspace{10pt}
    \includesvg[height=50pt]{./Whitepaper_files/image1.svg}
\end{flushright}
```
:::


::: {.content-visible when-format="html"}
<div style="text-align: right; display: flex; align-items: center; justify-content: flex-end; gap: 30px; margin-top: 20px;">
  <a href="https://www.openaire.eu/">
    <img src="https://ssccs.org/images/openaire.svg" alt="Open AIRE" style="height: 40px; margin-right: 20px;">
  </a>
  <a href="https://cernandsocietyfoundation.cern/projects/zenodo">
  <img src="https://ssccs.org/images/cern.svg" alt="CERN Open Science" style="height: 80px;">
  </a>
</div>
:::