# SSCCS

## Schema–Segment Composition Computing System

Loops disappear into layout: A System where Structured Deployment is the Path, and Observed Synthesis is the Computation


# I. Ontological Break

## 1. The End of Instruction

For decades, computation has been defined as:

```
Data + Program → Execution → Result
```

This formulation rests upon several foundational assumptions that have remained largely unchallenged since the dawn of digital computing:

- Data exists as intrinsic value: Numbers, strings, and structures are treated as fundamental entities that can be stored, moved, and transformed.
- Programs act upon data: Algorithms are external agents that manipulate these values through sequences of operations.
- State mutation produces meaning: Change is the primary mechanism through which computation expresses itself.
- Time orders execution: The sequence of operations is considered essential to correctness.

SSCCS rejects this entire structure.

Computation is not the transformation of values. Computation is the collapse of structured potential.

There are no fundamental values. There are no intrinsic algorithms. There is no privileged timeline of execution.

What exists instead is:

- Structured possibility: The space of what could be, defined by immutable blueprints.
- Conditional constraints: Rules that determine which configurations are admissible.
- Observation: The singular event that collapses potential into actuality.
- Collapse: The moment where structure reveals itself as projection.

What we call a "result" is not produced through a sequence of operations. It is revealed through collapse — a momentary crystallization of what was always possible, given the constraints.

This shift is not merely semantic. It redefines the very nature of what it means to compute. In the traditional model, computation is a process of *becoming* through change. In SSCCS, computation is a process of *revealing* through observation. The system does not "become" something new; it exposes what it already is, layer by layer, collapse by collapse.


## 2. Collapse as Computation

In SSCCS:

> Computation is the collapse of a constraint manifold under observation.

A system does not execute instructions. It composes structure.

It does not mutate state. It reveals a cross-section of constrained possibility.

Consider the difference between these two perspectives:

- Traditional view: A program reads input values, applies a series of transformations, and produces output values. The algorithm is the hero; data is the passive substrate.
- SSCCS view: A constellation of immutable segments, structured by a scheme, exists within a field of constraints. Observation selects a particular configuration — a projection — from the space of possibilities. The structure itself is the computation; observation merely makes it visible.

Projection is not retrieval. It is boundary formation.

When a system projects, it does not fetch a pre-existing value from memory. It traces the boundaries of what is possible under current constraints, and what emerges is the shape of those boundaries themselves. The projection is not a stored datum; it is a transient geometric artifact of the constraint space.

What appears as output is merely the visible surface of a deeper structural reality — a shadow cast by the collapse of higher-dimensional possibility onto the plane of observation.

This perspective dissolves the traditional dichotomy between program and data. There is no separation between "code" and "information" because there is no code in the conventional sense. There are only structures and their collapses. The program is not a set of instructions; it is the geometry of possibility itself.


## 3. The De-privileging of Time

Traditional computing treats time as fundamental:

- Instruction order determines correctness.
- Clock cycles measure progress.
- Sequential causality defines relationships between events.

These assumptions are so deeply embedded that they appear inseparable from computation itself. Yet they are not laws of nature; they are engineering choices inherited from the von Neumann architecture.

SSCCS treats time as just another coordinate.

Temporal ordering is not execution. It is comparison along a dimension.

Just as spatial coordinates allow us to say "this point is to the left of that point," temporal coordinates allow us to say "this observation occurred before that observation." But this ordering carries no special significance. It does not imply causation. It does not define the flow of computation. It is simply one axis among many in a multi-dimensional coordinate space.

There is no "flow" in the system. There is only structure and its collapse.

This has profound consequences:

- Parallelism becomes natural: If time does not impose a global order, independent collapses can occur simultaneously without coordination.
- Causality becomes local: Relationships between collapses are defined by structural adjacency, not by temporal sequence.
- Determinism is preserved: Identical structures under identical constraints produce identical projections, regardless of when or in what order collapses occur.

The removal of time as a privileged dimension liberates computation from the tyranny of sequentiality. What remains is a purely structural universe where order is merely a relation, not a ruler.


# II. The Structural Ontology

SSCCS consists of three ontological layers, each distinct and irreducible:

```
Segment → Scheme → Field
                  ↓
              Observation
                  ↓
              Projection
```

Each layer has its own role, its own properties, and its own relationship to the others. Together, they form the complete computational ontology.


## 4. Segment: Atomic Coordinate Existence

A Segment is the minimal indivisible unit of potential — the atom of the SSCCS universe.

It:

- Is immutable: Once created, it cannot be modified, only referenced.
- Contains no value: It holds no numbers, strings, or data structures.
- Contains no state: It has no mutable properties, no runtime variability.
- Contains only:
  - Coordinates: Positions in a multi-dimensional possibility space, with all dimensions treated equivalently.
  - Identity: A cryptographic hash derived from its intrinsic properties, providing verifiable uniqueness.

A Segment does not define meaning. It does not define dimensionality. It does not define adjacency.

It merely exists as a coordinate point in possibility space.

> Segment is existence without interpretation.

This may seem minimal to the point of vacuity, but it is precisely this minimalism that enables the power of SSCCS. Because a Segment is nothing but a point of existence, it can be composed with other Segments without conflict. Because it contains no mutable state, it can be observed concurrently by any number of observers without synchronization.

The consequences of Segment immutability are far-reaching:

- Concurrent observation without conflict: Multiple observers can examine the same Segment simultaneously, because observation does not modify the Segment. No locks, no mutexes, no race conditions.
- Deterministic reproducibility guaranteed: A Segment's identity is fixed; its coordinates are fixed. Any observation of that Segment under identical field conditions will yield identical projections. Reproducibility is not a property to be tested; it is an ontological necessity.
- Elimination of mutation-based race conditions: The classic bugs of concurrent programming — data races, deadlocks, livelocks — all stem from mutable state. Segments have no mutable state, so these bugs cannot arise.

In a universe built from Segments, the foundational problems of concurrent programming simply disappear. They are not solved; they are rendered meaningless.


## 5. Scheme: Structural Blueprint

If Segment is existence,Scheme is structure.

A Scheme:

- Is immutable: Like Segments, Schemes are fixed once defined.
- Defines dimensional axes: Specifies the coordinate systems within which Segments exist.
- Defines internal structural constraints: Rules that govern how Segments may relate to one another.
- Defines adjacency relations: Specifies which Segments are neighbors in possibility space.
- Defines memory layout semantics: Determines how structural relations map to physical storage.
- Defines collapse rules: Specifies how observation resolves constraints into projections.

The Scheme determines how Segments compose.

It encodes:

- Geometry of possibility: The shape of the space within which Segments exist.
- Topology of relation: The connectivity patterns that define adjacency and composition.
- Structural meaning: The semantics that emerge from configuration, not from interpretation.

Most critically:

> Specification becomes circuit.

The Scheme is not code. It is structural law.

When a Scheme is defined, it does not describe a sequence of operations to be performed. It describes a geometry to be instantiated. The relationship between Segments is not temporal; it is spatial. Adjacency is not a step in an algorithm; it is a connection in a graph.

This redefinition has profound implications for how we understand compilation, optimization, and execution.


### 5. 1 Compilation Reinterpreted

In traditional computing, compilation transforms source code into machine instructions: a sequence of operations that a processor can execute. This model assumes that computation is fundamentally about performing steps in order.

In SSCCS, compilation does not produce executable instructions.

It performs:

> Structural mapping of Scheme geometry into hardware topology.

The compiler's job is not to generate code but to lay out structure — to map the abstract geometry of Segments and Schemes onto the physical geometry of memory and processing elements.

Because Segments are immutable and layout is declared structurally, the compiler can make far-reaching optimizations that were previously impossible or required heroic manual effort:

- SIMD vectorization becomes implied: When a Scheme defines a collection of Segments with parallel structure, the compiler can map them directly to vector units without analyzing loop dependencies.
- Memory locality becomes determined: The Scheme's adjacency relations tell the compiler which Segments should be placed near each other in physical memory. Cache efficiency is not a runtime optimization; it is a compile-time certainty.
- Parallel scheduling becomes natural: Independent subgraphs in the Scheme imply independent computations. The compiler can schedule them across cores without analyzing data dependencies.
- Synchronization becomes unnecessary: Immutability guarantees that concurrent observations cannot conflict. No locks, no barriers, no atomic operations.

Manual optimization dissolves into structure.

What programmers once spent years mastering — data layout, cache alignment, vectorization, thread safety — becomes an automatic consequence of structural specification. The Scheme says *what* should exist; the compiler determines *how* to map it to hardware. The programmer no longer optimizes; they specify.


## 6. Field — Dynamic Constraint Substrate

The Field is the only mutable layer in SSCCS.

It:

- Contains external constraints: Rules and conditions that are not of the immutable Scheme but affect observation.
- Maintains relational topology: The dynamic structure of how constraints relate to one another.
- Defines observation frontier: Which regions of the constraint space have already been collapsed.

Crucially, the Field does not store values. It stores admissibility conditions — the rules that determine which configurations are possible.

Field mutation:

- Is explicit: Changes to the Field are deliberate operations, not implicit side effects.
- Is deterministic: Given the same initial state and same mutation operation, the resulting Field state is always the same.
- Does not "evolve over time": Time is not a privileged dimension; mutations occur at specific coordinates, which may include temporal coordinates but are not defined by them.
- May reconfigure observable regions: Changing the Field can make previously unobservable configurations visible, or vice versa.

The Field is where the dynamic aspect of computation lives. While Segments and Schemes provide immutable structure, the Field provides mutable context. An observation evaluates the current state of the Field against the immutable structure of Segments and Schemes, producing a projection that reflects both.

Time is simply another coordinate axis within the Field — one dimension among many, with no special status.


# III. Observation Formalism

## 7. Observation — The Sole Active Event

Observation is the only mechanism that produces actuality in SSCCS.

Formally:

```
(Segment set structured by Scheme)
+
(Field state)
→ Observation
→ Projection
```

Observation:

- Occurs at structural instability: The points where constraints conflict, where possibilities bifurcate, where the system cannot remain undetermined.
- Resolves constraint conflicts: When multiple constraints compete, observation determines the resolution.
- Collapses potential into projection: The space of possibility crystallizes into a single actual configuration.
- Is internally triggered: Observation arises from the structure itself, not from an external clock or scheduler.
- Is deterministic: Under identical conditions, identical observations yield identical projections.

There is no other active process in SSCCS.

No instruction cycle. No hidden execution engine. No background scheduler. No implicit state machine.

The entire dynamics of computation reduce to a single question: When does structure demand observation?

This perspective inverts the traditional relationship between program and execution. In conventional systems, execution is the default; the program runs continuously unless explicitly halted. In SSCCS, stasis is the default; observation occurs only when structure requires it. Computation is not a continuous flow but a sequence of discrete collapses, each triggered by structural necessity.


## 8. Projection — Ephemeral Actuality

Projection:

- Is transient: It exists only at the moment of observation.
- Is not stored: Projections are not written to memory; they are events, not states.
- Is not intrinsic value: A projection does not represent a number or a string; it represents a collapsed configuration.
- Is not persistent state: The system does not "remember" projections unless they are used to mutate the Field.

It is:

> The collapsed cross-section of observable degrees of freedom.

Think of a projection as a photograph of a crystal at the moment of its formation. The photograph captures the structure that emerged, but it is not the crystal itself. The crystal persists; the photograph is ephemeral. In SSCCS, the Segments and Scheme persist; the projection is the momentary image of their configuration under current Field constraints.

If a projection is needed again, it must be regenerated through observation. There is no cache of previous results unless the Field explicitly stores them as new constraints — and even then, what is stored is a constraint, not a value.

This ephemerality is not a limitation; it is a feature. By refusing to treat projections as persistent entities, SSCCS eliminates entire classes of bugs related to stale data, cache invalidation, and state inconsistency. What you observe is what exists at that moment; nothing is carried forward unless explicitly preserved through Field mutation.

Segments remain untouched. Scheme remains untouched. Field remains structurally intact unless explicitly mutated.


# IV. Collapse Theory of Computation

SSCCS proposes a new computational identity — a fundamental redefinition of what computation is:

| Traditional       | SSCCS                     |
| ----------------- | ------------------------- |
| Execution         | Collapse                  |
| State mutation    | Constraint resolution     |
| Data processing   | Structure observation     |
| Algorithm         | Geometry                  |
| Result            | Projection                |
| Program           | Blueprint                 |
| Compilation       | Structural mapping        |
| Concurrency       | Implicit parallelism      |
| Synchronization   | Immutability              |
| Optimization      | Layout                    |
| Time              | Coordinate dimension      |
| Memory            | Constraint substrate      |
| Processor         | Observation engine        |

This is not merely a translation of terms; it is a complete reorientation of the computational worldview.

Computation is not a sequence. It is a collapse event.

In traditional computing, a program is a story told over time — a narrative of state changes, each building on the last. In SSCCS, a program is a landscape of possibility, and computation is the moment when the landscape reveals a particular configuration. There is no narrative; there is only geometry and its revelation.

Parallelism is not managed. It is implied by structural independence.

When Segments are independent in the Scheme, they can be observed concurrently without any coordination. The programmer does not "add parallelism"; they simply specify structure, and parallelism emerges naturally from the geometry. This is not a optimization technique; it is a fundamental property of the model.

Energy is not distributed per instruction. It concentrates at observation.

In von Neumann architectures, every instruction consumes energy, whether it produces meaningful results or not. In SSCCS, energy is consumed only when observation occurs — when potential collapses into actuality. This aligns with physical intuition: a system in equilibrium consumes no energy; change requires work. Observation is the moment of change; everything else is stasis.


# V. Engineering Consequences

The philosophical break yields practical effects that can be measured, implemented, and deployed.

SSCCS automates what programmers historically performed manually:

| Manual Optimization     | SSCCS Automation                             |
| ----------------------- | -------------------------------------------- |
| Data layout orchestration | Scheme defines geometry; compiler maps to hardware |
| Cache alignment         | Adjacency relations determine physical proximity |
| SIMD vectorization      | Parallel structure implies vector operations |
| Thread scheduling       | Independent subgraphs map to independent cores |
| Lock management         | Immutability eliminates need for locks       |
| Algorithm selection     | Collapse rules determine resolution strategy |

Consider a concrete example:

```rust
// Traditional imperative approach
let mut sum = 0;
for i in data {
    sum += i;  // Loop overhead, state tracking, sequential dependency
}

// SSCCS approach
let projection = field. observe::<Adder>(segments);
// Scheme already knows the structure
// Compiler maps to SIMD automatically
// No loop, no mutable state, no sequential dependency
```

In the traditional approach, the programmer must manage:

- Loop boundaries and indices
- Accumulator state and its initialization
- Sequential dependencies between iterations
- Potential for parallelization (if attempted)
- Cache behavior of data access patterns

In the SSCCS approach, the programmer simply specifies:

- A set of Segments (the data elements)
- A Scheme defining their structure (here, an Adder scheme)
- A Field providing context (if any)

The compiler then:

- Analyzes the Scheme to understand the relationship between Segments
- Determines that they are independent and can be processed in parallel
- Maps them to SIMD units if available
- Lays them out in memory for optimal cache utilization
- Generates observation logic that collapses the structure into a projection

Loops disappear into layout. State disappears into structure. Synchronization disappears into immutability.

This is not incremental improvement; it is qualitative transformation.


## The Automation of Manual Optimization

To appreciate the depth of this transformation, consider what "manual optimization" has historically entailed:

- Data layout: Programmers spend hours arranging structs, padding fields, aligning to cache lines — all to coax the hardware into performing efficiently.
- Cache locality: Data structures are carefully designed to keep related data together, to prefetch intelligently, to avoid cache misses.
- Vectorization: Loops are unrolled, operations are reordered, intrinsics are used — all to utilize SIMD units.
- Thread safety: Locks are placed, atomic operations are chosen, memory ordering is specified — all to prevent races.
- Algorithm selection: Different algorithms are chosen based on input size, data characteristics, hardware capabilities.

Each of these is a manual optimization — knowledge and effort applied by the programmer to make the system run faster.

SSCCS renders these optimizations automatic:

- Layout is determined by the Scheme's geometry, not by the programmer's guesswork.
- Locality follows from adjacency; if the Scheme says two Segments are adjacent, they will be placed together.
- Vectorization is implied by parallel structure; if Segments are independent, they can be processed in parallel.
- Thread safety is guaranteed by immutability; if nothing changes, nothing can race.
- Algorithm selection is encoded in collapse rules; the Scheme specifies how resolution should occur.

The programmer no longer optimizes; they specify. The system does the rest.


# VI. Hardware Horizon

The ultimate implication of SSCCS is architectural.

If Scheme defines structure and layout, then:

> Hardware may directly embody blueprint geometry.

This is not science fiction; it is a logical consequence of the model. When computation is collapse rather than execution, the processor's job is not to interpret instructions but to instantiate structure. When data is immutable and observation is atomic, the memory hierarchy's job is not to cache values but to maintain constraint topology.

Observation-centric architectures become possible.

Consider the implications:

- No instruction decoding: If there are no instructions to decode, the front-end of modern processors — with its complex pipelines, branch predictors, and speculative execution — becomes unnecessary.
- No memory hierarchy: If data is laid out according to Scheme geometry and never moves, caches become irrelevant. Memory is the processor; the processor is memory.
- No synchronization: If all observations are of immutable structures, locks and atomic operations disappear. Concurrency is free.
- Energy concentration: If computation only occurs at observation, energy is spent only when work is done. Idle systems consume no power.

Memristor-based architectures provide a concrete example of how this might be realized. Memristors can store state and perform logic in the same physical element, blurring the distinction between memory and processor. A memristor array can directly embody a constraint graph; observation can collapse that graph through physical processes, not software simulation.

Future processors may:

- Collapse constraints directly through analog or hybrid computation
- Eliminate instruction decoding entirely
- Unify memory and logic at the physical level
- Concentrate energy at observation points, achieving thermodynamic efficiency

This is not a distant dream. It is a roadmap:

| Phase | Implementation | Characteristics |
|-------|---------------|-----------------|
| 1 | Software emulation (Rust) | Proof of concept, validation, refinement |
| 2 | Hardware acceleration (FPGA/PIM) | Structural mapping to reconfigurable logic |
| 3 | Native observation-centric processors | Direct collapse in physical substrate |

In Phase 1, Rust provides a "projector" — an engine that reads `.ss` blueprints and performs observation in software. This validates the model and builds the toolchain.

In Phase 2, FPGAs and PIM architectures accelerate the mapping from Scheme to hardware, demonstrating the performance potential of structural computation.

In Phase 3, processors designed specifically for observation replace general-purpose CPUs, realizing the full vision of collapse-based computation.

Throughout this progression, the `.ss` blueprint remains unchanged. The same specification that runs in software emulation today will run on native observation processors tomorrow. The format outlives the implementation.


# VII. Validation Domains

SSCCS is not merely theoretical; it has concrete applicability across multiple domains where traditional approaches struggle.

| Domain               | Traditional Challenge                          | SSCCS Advantage                              |
| -------------------- | ---------------------------------------------- | -------------------------------------------- |
| Climate modeling     | Massive state space, complex constraints       | Constraint isolation, deterministic collapse |
| Space systems        | Radiation-induced errors, power constraints    | Structural reproducibility, observation-concentrated energy |
| Protein folding      | Combinatorial explosion, time scales           | Massive parallel collapse, structural decomposition |
| Swarm robotics       | Coordination overhead, failure modes           | Recursive composition, emergent coordination |
| Financial modeling   | Real-time constraints, complex dependencies    | Predictable collapse, dependency isolation   |
| Cryptographic systems | Side-channel attacks, verification complexity | Immutable structure, formal verification     |
| Autonomous vehicles  | Sensor fusion, real-time decision making       | Constraint-based observation, deterministic response |

In each domain, the fundamental shift from execution to collapse offers advantages that incremental optimization cannot provide:

Climate modeling requires simulating interactions across multiple scales with complex physical constraints. Traditional approaches battle state explosion and numerical instability. SSCCS treats constraints as first-class entities; collapse reveals the physically admissible configurations without iterating through impossible states.

Space systems operate in radiation-heavy environments where bit flips and transient errors are common. Traditional systems add redundancy and error correction, consuming power and complexity. SSCCS's immutable Segments and deterministic collapse make many errors structurally impossible; a flipped bit in a Segment changes its identity, making it a different Segment entirely — easily detected and isolated.

Protein folding involves exploring a combinatorial space too large for exhaustive search. Traditional approaches use heuristics and approximations. SSCCS's parallel collapse can explore many regions simultaneously; the structure itself guides the observation process toward physically meaningful configurations.

Swarm robotics requires coordinating multiple independent agents with limited communication. Traditional approaches centralize control or implement complex consensus protocols. SSCCS's recursive composition allows each robot to be a projection of a shared blueprint; coordination emerges from shared structure, not explicit communication.


# VIII. Transcendence Pathway

SSCCS is not a destination but a direction. The roadmap reflects this:

## Phase 1 — Software Emulation

- Implement core concepts in Rust
- Define `.ss` open format
- Build observation engine
- Validate with simple domains
- Establish toolchain and community

*Goal: Prove the model works.*

## Phase 2 — Hardware Acceleration

- Map Schemes to FPGA fabric
- Explore PIM architectures
- Demonstrate performance scaling
- Refine structural mapping techniques
- Build bridges to existing systems

*Goal: Show the model performs.*

## Phase 3 — Native Observation-Centric Processors

- Design processors that collapse directly
- Eliminate instruction decode
- Unify memory and logic
- Achieve thermodynamic efficiency
- Enable new classes of applications

*Goal: Realize the model's full potential.*

Performance is not the first objective. Structural fidelity is.

Before we can optimize, we must understand. Before we can accelerate, we must validate. The pathway is deliberate: prove, perform, perfect.


# IX. The Open Format

Central to SSCCS is the `.ss` open format — a human-readable, machine-processable representation of Segments and Schemes.

Inspired by Markdown's success, `.ss` files are:

- Human-readable: Designed to be written and understood by people, not just machines.
- Machine-processable: Structured for efficient parsing and compilation.
- Immutable by default: Once defined, a `.ss` blueprint does not change; evolution creates new versions.
- Cryptographically identifiable: Each Segment has a hash-based identity, ensuring verifiability.
- Compositional: Schemes can include other Schemes; Segments can reference other Segments.
- Platform-independent: The format outlives any particular implementation.

A minimal `.ss` file might look like:

```
# Simple Counter System

## Segment Definitions
:::segment {id: "counter", type: "integer"}
initial: 0
:::

## Scheme Definition
:::scheme {id: "increment", input: "@counter"}
rule: "counter + 1"
output: "new_counter"
:::

## Field Initialization
:::field {id: "main"}
include: "@counter"
:::
```

This is not code; it is specification. It describes what exists, not what to do. The observation engine reads this specification and performs collapses accordingly — either by compiling to native code (Phase 1), mapping to FPGA (Phase 2), or directly instantiating in hardware (Phase 3).

The format is the program. The engine is the projector. The implementation changes; the specification persists.


# X. Philosophical Implications

Beyond engineering, SSCCS carries philosophical weight.

It suggests that:

- Computation is not about change but about revelation.
- Structure is more fundamental than process.
- Time is not a river but a coordinate.
- Value is not intrinsic but projected.
- Programs are not recipes but blueprints.
- Results are not products but shadows.

These are not merely poetic statements; they are operational truths within the model. They guide design decisions, inform optimization strategies, and shape the way we think about what computing is.

In the traditional view, a computer is a factory: raw materials (data) go in, instructions (program) guide the machinery, and products (results) come out. The factory runs continuously, consuming energy whether it's producing or not.

In the SSCCS view, a computer is a crystal: structure (blueprint) defines what can exist, context (field) determines current conditions, and observation (collapse) reveals momentary configurations. The crystal does nothing until observed; observation consumes energy only when it occurs.

This shift from process ontology to structure ontology has implications far beyond computing. It touches on questions of what it means for something to exist, what it means for something to change, and what it means for something to be known.

SSCCS does not answer these questions, but it provides a framework within which they can be asked differently. And sometimes, asking differently is the first step toward understanding.


# Final Declaration

SSCCS establishes:

- Composition as primitive.
- Structure as executable law.
- Observation as sole act.
- Projection as ephemeral actuality.
- Time as coordinate, not ruler.
- Immutability as foundation.
- Specification as circuit.

Programs become structured blueprints. Compilation becomes structural mapping. Execution becomes collapse. Optimization becomes layout. Concurrency becomes independence. Synchronization becomes immutability.

There is no instruction stream, is only structure  and the moment it collapses.
 

*"Data is merely the shadow of a collapsed state."*

---

© 2026 SSCCS gUG (i. G.), a German non-profit research initiative. All rights reserved.
- Document authenticity verifiable via GPG-signed commits (Key ID: BCCB196BADF50C99) in github. com/ssccsorg.
- The foundation of the content was conceived by the human author, with generative AI (Gemini/GPT) assisting in structural refinement, clarity, and technical consistency.